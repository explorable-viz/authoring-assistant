let split [] = ([], []);
    split (x : xs) =
      let (ys, zs) = split xs in (x : zs, ys);

let merge xs ys =
       match (xs, ys) as {
          ([], _) -> ys;
          (x : xs', []) -> xs;
          (x : xs', y : ys') ->
             if x < y
             then x : merge xs' ys
             else y : merge xs ys'
       };

let mergesort xs =
       if length xs < 2
       then xs
       else
          let (ys, zs) = split xs in
          merge (mergesort ys) (mergesort zs);

-- assume data is sorted
let findQuantile q p data = 
    let rank = (p / q) * (length data - 1)
    in if rank == floor rank
    then nth rank data
    else let x1 = floor rank;
             x2 = ceiling rank;
             left = nth x1 data;
             right = nth x2 data
        in left + (rank - x1) * (right - left);

let findPercentile = findQuantile 100;

let split p data = 
    let go fls trs [] = (fls, trs);
        go fls trs (x : xs) = 
            if p x
            then go fls (x : trs) xs
            else go (x : fls) trs xs
    in go [] [] data;

let accumBins data [] = [];
    accumBins data (r : es) =  
        let (ge, le) = split (fun x -> x <= r) data
        in le : accumBins ge es;        

let cut data nbins = 
    let low = minimum data;
        binwidth = (maximum data - low) / nbins;
        edges = [ low + (x * binwidth) | x <- enumFromTo 1 nbins ]
    in (accumBins data edges, binwidth);

let qcut data nbins = 
    let low = minimum data;
        edges = [ findQuantile nbins x data | x <- enumFromTo 1 nbins]
    in accumBins data edges;

let likelihoodLE data target = 
    length (filter (fun x -> x <= target) data) / length data;

let likelihoodGE data target = 
    length (filter (fun x -> x >= target) data) / length data;
