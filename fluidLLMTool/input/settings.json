{
  "temperature": "0.3",
  "timeout": "1800",
  "num_ctx": "4000",
  "openai-token": "",
  "gemini-token": "",
  "gemini-projectId": "",
  "gemini-location": "",
  "claude-token": "",
  "ollama-url": "http://127.0.0.1",
  "ollama-port": "11434",
  "log-path": "logs/",
  "fluid-compiler-path": "./fluid-parser",
  "fluid-temp-file": "llmTest",
  "agent-limit": "5"
}