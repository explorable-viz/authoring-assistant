\begin{abstract}
\todo{Bit long?} We introduce \emph{transparent documents}, interactive web-based scholarly articles which allow readers
to explore the relationship to the underlying data by hovering over fragments of text, and present an LLM-based tool for
authoring transparent documents, building on recent developments in data provenance for general-purpose programming
languages. Our implementation uses Fluid, an open source programming language with a provenance-tracking runtime. Our
agent-based tool supports a human author during the creation of transparent documents, identifying fragments of text
which can be computed from data, such as numerical values selected from records or computed by aggregations like sum and
mean, comparatives and superlatives like ``better than'' and ``largest'', trend-adjectives like ``growing'', and similar
quantitative or semi-quantitative phrases, and then synthesising suitable Fluid queries over the data which generate the
target strings. The resulting expressions are inserted into the article's web page, turning the static text fragment
into an interactable data-driven element able to reveal the data that underwrites the natural language claims. We
evaluate our approach on a subset of SciGen, an open source dataset consisting of tables from scientific articles and
their corresponding descriptions, which we extend with hand-generated counterfactual test cases to evaluate how well
machine-generated expressions generalise. Our results show that gpt4o \todo{revisit} is often able to synthesise
compound expressions extensionally compatible with our gold solutions.
\end{abstract}
