\begin{abstract}
We introduce the idea of \emph{transparent documents}, web-based data-driven scholarly articles which allow
readers to explore the relationship to the underlying data by hovering over fragments of text. We present an
agent-based LLM framework for authoring transparent documents, building on recent developments in data
provenance for general-purpose programming languages. In particular we build on Fluid, an open source
functional programming language with a provenance-tracking runtime, which we use as a target platform. Our
tool consists of two LLM agents which support a human author during the creation of a transparent document. A
\SuggestionAgent helps identify fragments of text which could plausibly be computed from data, including
numerical values selected from records or computed by aggregations like sum and mean, comparatives and
superlatives like ``better than'' and ``largest'', trend-adjectives like ``growing'', and other idiomatic
quantitative or semi-quantitative phrases. An \InterpretationAgent, given such a fragment, then attempts to
synthesise a suitable Fluid query over the data which will generate the target string. Our tool then
interprets the resulting expression in the context of an interactive web page, which turns the generated text
into an interactable element able to reveal the relevant data. We evaluate our approach on a subset of SciGen,
an open source dataset consisting of tables from scientific articles and their corresponding descriptions,
which we extend with hand-generated counterfactual test cases to evaluate how well machine-generated
expressions generalise in the presence of changes to the underlying data. Our results show that some
state-of-the-art models are often able to synthesise compound expressions that are extensionally compatible
with our gold solutions.
\end{abstract}
