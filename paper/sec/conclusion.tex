\section{Conclusions and Future Work}
\label{sec:conclusion}

\subsection{Future Work}
\label{sec:conclusion:future-work}

\begin{itemize}
\item Till now we have assumed that helpers functions such as \kw{growShrink} and \kw{trendWord} are
predefined. Add support for LLM query results that introduce definitions, perhaps adding a loopback condition
which turns "Definition not found" errors into an augmented prompt to generate the appropriate definition.
\item Extend prompt with values of variables in scope. We include statically known data sets into the prompt,
but realistic data analyses make use of derived data resulting from cleaning, imputation, aggregation, etc.
Natural language interpretation will likely proceed more accurately if we are able to include the values of
some of these intermediate queries into the prompt as well, perhaps treating the prompt as a notebook-like
script combining code fragments and their values.
\item A related observation is that much of the natural language present in scholarly articles refer to
\emph{visualisations}. Indeed, these also sometimes arise as intermediate artifacts in notebooks and similar
workflows. These too should be made available to the LLM, perhaps as structured data rather than mere bitmaps,
as one possible target for interpreting natural language claims (for example claims about trends often refer
directly to charts).
\item IDE integration. The implementation described in \secref{authoring-workflow} is a design prototype only,
with no IDE integration. We plan to add integrate this into VSCode or Cursor, providing a smooth authoring
experience for content creators.
\end{itemize}

LINK tags #109

IDE integration

Further validation of generated expressions (e.g. by generating counterfactual test cases)