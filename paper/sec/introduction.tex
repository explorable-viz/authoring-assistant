\section{Introduction: Transparent, Data-Driven Documents}

Making sense of and verifying data-driven claims is hard, even when the evidence base lives in the public
domain. A key challenge lies in tracing specific claims back to the underlying data. In peer review, for
example, empirical claims typically lack author-supplied links to data, making it hard for reviewers to check
them directly~\citep{weber20}. Paper retractions, meanwhile, are often attributable not to fraud, but to
simple errors in data management or analysis~\citep{hu25}. Large language models (LLMs) can assist with
fact-checking~\citep{abu-ahmad25} and interpretation of charts and figures~\citep{roberts24}, but current LLM
interfaces do not support direct interrogation of visual or other outputs.

Recent work on data provenance and data visualisation~\citep{psallidas18smoke,perera22,bond25}, on the other
hand, takes a more infrastructural approach to the transparency problem, by linking visualisations to their
data sources directly. This allows visual outputs to support in situ \emph{provenance queries}, user
interactions (e.g. mousing over a visual element) that reveal how visual features relate to data. The value
proposition of these approaches is that the interactions are provided automatically via trusted
infrastructure, namely a query language or general-purpose programming language which tracks dependencies as
data flows through a computation. However, these approaches to transparency only support direct interrogation
of outputs computed from data, such as visualisations. The accompanying natural language, which often plays a
central role in making the claims of the paper, remains hard to interpret.

In this paper, we make the case for combining these two approaches, leveraging the ability of LLMs to
understand complex technical natural language and to synthesise programs that express the analyses that
underwrite those claims, and extend interactive provenance queries to the natural language that accompanies
the charts and figures.  ..language which also makes quantitative statements and contains substantial implicit
analytic content. In principle transparent programming languages can also be used to create natural language
which is bidirectly linked to data, by computing key fragments of natural language from data. The following
example, adapted from \cite{zhang18} via \cite{moosavi21}, shows how the language presented in this paper can
be used to achieve this \rpnote{Need to illustrate counterfactual/generalisability}:

\begin{figure}%[h]
    \centering
    \includegraphics[width=\linewidth]{fig/scigen-1805.02474v1-10-with-pointer.png}
    \vspace{1mm}
    \hrule
    \includegraphics[width=\linewidth]{fig/scigen-1805.02474v1-10-counterfactual-with-pointer.png}
    \caption{\emph{Transparent document} example, showing data-driven natural language (top
    vs.~bottom)}\label{fig:scigen-example-website}
\end{figure}

We envisage two possible use cases for transparent text:

\begin{enumerate}
\item \textbf{Authoring.} Someone authoring content for an online article, wants to create text
linked to raw data (and derivative data such as charts or tabular summaries), so that the evidence base for
the claims made in the text can be explored \emph{in situ}, by interacting with the text.

\item \textbf{Reading or reviewing.} Someone reading textual claims derived from open data (e.g. a
scientific paper or climate report), wants to retroactively link the text to queries over the available data
and gradually ``rationally reconstruct'' the relationship between the claims in the paper and the evidence
base. Perhaps just to aid their own comprehension, or to provide some kind of justified peer review.
\end{enumerate}

\input{fig/scigen-1805.02474v1-10-src}

\subsection{Target idioms of natural language}

NLP aspect of the problem is potentially a big problem space in itself. We will restrict interest to certain
idiomatic uses of natural language in making/justifying scientific claims. Table~\ref{tab:fluid_examples}

\input{fig/natural-language-forms}

\subsection{Contributions}

\begin{itemize}
    \item Design and proof-of-concept implementation of AI-assisted workflow for authoring transparent text
    (\secref{authoring-workflow})
    \item Empirical evaluation of how effective current LLMs are at providing the ``AI-assisted'' part
\end{itemize}
