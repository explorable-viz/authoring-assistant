\section{Introduction: Transparent, Data-Driven Documents}

Making sense of and verifying data-driven claims is hard, even when the evidence base lives in the public
domain. A key challenge lies in tracing specific claims back to the underlying data. In peer review, for
example, empirical claims typically lack author-supplied links to data, making it hard for reviewers to check
them directly~\citep{weber20}. Paper retractions, meanwhile, are often attributable not to fraud, but to
simple errors in data management or analysis~\citep{hu25}. Large language models (LLMs) can assist with
fact-checking~\citep{abu-ahmad25} and interpretation of charts and figures~\citep{roberts24}, but currently
LLM interfaces do not support direct interrogation of visual outputs.

Recent work on data provenance and data visualisation~\citep{psallidas18smoke,perera22,bond25}, on the other
hand, approaches the transparency problem from this direction, through software infrastructure which
transparently connections charts and figures to their data sources. \rpnote{Contrast with LLM-based approach
-- trusted infrastructure.} This enables visual outputs to provide interactive \emph{provenance queries}, user
interactions (e.g. mousing over a visual element) that allow readers to explore how visual features relate to
data. The value proposition of these approaches is that the interactions are provided automatically via
trusted infrastructure, namely an underlying programming language (say query language or general-purpose
language) which tracks dependencies as data flows through a computation. However, these approaches are limited
to outputs computed from data, which usually precludes natural language, despite the fact that the main claims
of a paper are usually made using natural language, with charts and figures only playing a supporting role.

In this paper, we make the case for combining these two approaches, leveraging the ability of LLMs to
understand complex technical natural language and to synthesise programs that express the analyses that
underwrite those claims, and extend interactive provenance queries to the natural language that accompanies
the charts and figures.  ..language which also makes quantitative statements and contains substantial implicit
analytic content. In principle transparent programming languages can also be used to create natural language
which is bidirectly linked to data, by computing key fragments of natural language from data. The following
example, adapted from \cite{zhang18} via \cite{moosavi21}, shows how the language presented in this paper can
be used to achieve this \rpnote{Need to illustrate counterfactual/generalisability}:

\begin{figure}%[h]
    \centering
    \includegraphics[width=\linewidth]{fig/scigen-1805.02474v1-10-with-pointer.png}
    \vspace{1mm}
    \hrule
    \includegraphics[width=\linewidth]{fig/scigen-1805.02474v1-10-counterfactual-with-pointer.png}
    \caption{\emph{Transparent document} example, showing data-driven natural language (top
    vs.~bottom)}\label{fig:scigen-example-website}
\end{figure}

We envisage two possible use cases for transparent text:

\begin{enumerate}
\item \textbf{Authoring.} Someone authoring content for an online article, wants to create text
linked to raw data (and derivative data such as charts or tabular summaries), so that the evidence base for
the claims made in the text can be explored \emph{in situ}, by interacting with the text.

\item \textbf{Reading or reviewing.} Someone reading textual claims derived from open data (e.g. a
scientific paper or climate report), wants to retroactively link the text to queries over the available data
and gradually ``rationally reconstruct'' the relationship between the claims in the paper and the evidence
base. Perhaps just to aid their own comprehension, or to provide some kind of justified peer review.
\end{enumerate}

\input{fig/scigen-1805.02474v1-10-src}

\subsection{Target idioms of natural language}

NLP aspect of the problem is potentially a big problem space in itself. We will restrict interest to certain
idiomatic uses of natural language in making/justifying scientific claims. Table~\ref{tab:fluid_examples}

\input{fig/natural-language-forms}

\subsection{Contributions}

\begin{itemize}
    \item Design and proof-of-concept implementation of AI-assisted workflow for authoring transparent text
    (\secref{authoring-workflow})
    \item Empirical evaluation of how effective current LLMs are at providing the ``AI-assisted'' part
\end{itemize}
