\section{Related Work}
\label{sec:related}

\paragraph{Argument mining.}
For over fifteen years the field of NLP has been exploring the problem of argument mining, which involves identifying argumentative structures in text, such as claims, premises, and conclusions, and
mapping them to formal representations~\citep{palau2009argumentation,lippi2015argument} . Early work in this area focused on rule-based approaches, while more recent work has leveraged machine learning and deep learning techniques to improve
performance~\citep{stab2014identifying,stab2017parsing,eger2017neural}. The field has also emphasized defining annotation schemes for the task, such as the Argumentative Zoning framework~\citep{teufel2002summarizing,teufel2009towards} }, as well as schemes more directly tailored to argument mining~\citep{stab2014annotating}.
The field has focused on various domains, starting from legal texts~\citep{toulmin2003uses}, and has relied on online resources such as Debatepedia~\citep{cabrio2013natural}. The community has also rapidly engaged with work that explores the use of argument mining in scientific texts~\citep{liakata2012automatic,lauscher2018investigating} to better understand the structure of scientific arguments and the relationships between different claims and evidence. 
While the advent of LLMs has improved performance~\citep{gorur2025can,vrakatseli2025can}, argument mining remains a challenging task, particularly when it comes to identifying implicit argumentative relations between discourse units, and reasoning about relationships among different argumentative components â€” especially in cross-domain settings where models struggle to generalise~\citep{gemechu2024aries}. While in our work we do not directly perform traditional argument mining, our work similarly relies on the identification of claims in text, which we evaluate following established practices in the field.

\paragraph{NLP and scientific writing.} The intersection of NLP and scientific writing has gained increasing attention in recent years, with a focus on improving the clarity, coherence, and overall quality of scientific texts. Various approaches have been proposed, including the use of automated writing assistants, text simplification techniques, and tools for enhancing the argumentative structure of scientific papers~\citep{..,}. These efforts aim to support researchers in effectively communicating their findings and engaging with the broader scientific community.

\paragraph{Interpretable NLP.}

As we saw earlier \todo{ref}, scientific texts routinely make use of comparatives like ``faster'' while
leaving one of the argument slots implicit, with the context determining the omitted referent. LLMs
demonstrate considerable competence in resolving these and other more syntactic forms of anaphora such as
pronouns~\citep{zhu25}, but the resolved referent itself -- concretely, what was being referred to -- remains
implicit. Interpretable NLP is a recent research direction which aims to support comprehension (and
production) of text in a more explicit and transparent way~\citep{yulan23}. By generating code that formalises
the interpretation of a comparative like ``faster'', our approach also makes these implicit references
explicit; a richer version of our approach would allow the user to explore the linguistic interpretation as
well. \todo{WIP}
