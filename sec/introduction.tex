\section{Introduction}

\begin{itemize}
\item Making sense of data-driven claims is hard, even if the evidence base (code/data) is open
\item We see this in peer review, misinformation, retracted papers, â€¦
\end{itemize}

\begin{figure}[h]
   \includegraphics[width=0.9\textwidth]{fig/ipcc-mockup.png}
   \caption{Mockup of end-user transparency features (numbered 1 to 8)}
   \label{fig:ipcc-mockup}
\end{figure}

\subsection{Self-Certifying Text}

\begin{itemize}
\item Introduce basic idea, as complementary to transparent visualisations
\end{itemize}

\subsubsection{Use cases}
Two potential scenarios for this sort of technology:

\paragraph{Authoring transparent text.} Someone authoring content for an online article, wants to create text
linked to raw data (and derivative data such as charts or tabular summaries), so that the evidence base for
the claims made in the text can be explored \emph{in situ}, by interacting with the text.

\paragraph{Interpreting text after the fact.} Someone reading textual claims derived from open data (e.g. a
scientific paper or climate report), wants to retroactively link the text to queries over the available data
and gradually ``rationally reconstruct'' the relationship between the claims in the paper and the evidence
base. Perhaps just to aid their own comprehension, or to provide some kind of justified peer review.

\vspace{2mm}
\noindent Here we focus on the first one because the second one requires a certain amount of additional setup.

\subsubsection{Target idioms of natural language}

NLP aspect of the problem is potentially a big problem space in itself. We will restrict interest to certain
idiomatic uses of natural language in making/justifying scientific claims. Examples:



\begin{itemize}
\item quantitative expressions
\begin{itemize}
   \item pure numerical values
   \item percentages
   \item rounded or normalised numbers
\end{itemize}
\item aggregation
\begin{itemize}
   \item average
   \item totals
   \item count
\end{itemize}
\item trends
\begin{itemize}
   \item comparisons
   \item ranks
\end{itemize}
\item graded Adjectives (e.g.~\emph{virtually certain}, \emph{exceptionally unlikely})
\item references to visual elements and their parts (mereology)
\end{itemize}

\begin{table}[!ht]
   \centering
   \tiny
   \begin{tabular}{p{2cm}p{1.3cm}p{6.7cm}p{2cm}}
      \toprule
      Type & Category & Example & Status \\
      \midrule
      pure numerical values & Quantitative expressions & (findWithKey' "model" "LSTM" tableData).time\_s & Done \\
      percentages & Quantitative expressions &  "The Energy Sector accounts for total methane emissions of", (record.emissions / sum(map (fun x -> x.emissions) (getByYear year tableData))) * 100 & Done \\
      rounded or normalised numbers & Quantitative expressions & ~ & ~ \\
      average & Aggregation & "The average methane emissions for the year 2024 is", (sumEmissions year tableData / length records) & Done \\
      totals & Aggregation & "The total methane emissions for the year 2024 is", (sumEmissions year tableData) & Done \\
      count & Aggregation & ~ & ~ \\
      comparisons & Trends & trendWord (findWithKey' "model" "BiLSTM" tableData).time\_s (findWithKey' "model" "LSTM" tableData).time\_s "growing from" "shrinking to" "equal to" & Done \\
      ranks & Trends & let pos = findIndex "model" "CNN" (insertionSort cmpTime tableData) in rankLabel "lowest" pos & Done \\
      Graded adjectives  & Adjectives & ~ & ~ \\
      References to visual elements and their parts (mereology) & ~ & ~ & ~ \\
      \bottomrule
   \end{tabular}
\end{table}

\subsection{Contributions}

\begin{itemize}
\item Design and proof-of-concept implementation of AI-assisted workflow for authoring transparent text
(\secref{authoring-workflow})
\item Empirical evaluation of how effective current LLMs are at providing the ``AI-assisted'' part
\end{itemize}
