\section{Related Work}
\label{sec:related}

\paragraph{Interpretable NLP.}

As we saw earlier \todo{ref}, scientific texts routinely make use of comparatives like ``faster'' while
leaving one of the argument slots implicit, with the context determining the omitted referent. LLMs
demonstrate considerable competence in resolving these and other more syntatic forms of anaphor such as
pronouns~\citep{zhu25}, but the resolved referent itself -- concretely, what was being referred to -- remains
implicit. Interpretable NLP is a recent research direction which aims to support comprehension (and
production) of text in a more explicit and transparent way~\citep{yulan23}. By generating code that formalises
the interpretation of a comparative like ``faster'', our approach also makes these implicit references
explicit; a richer version of our approach would allow the user to explore the linguistic interpretation as
well. \todo{WIP}

\paragraph{Use of LLMs to interpret scientific documents.}

The ability of LLMs to interpret natural language in scientific contexts has been studied extensively, for
example quantity extraction~\citep{bolucu23}, scientific fact-checking~\citep{abu-ahmad25}. todo{interpreting
figures}

\paragraph{Transparent programming languages.}

\cite{perera22,bond25,psallidas18smoke}
