{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "One annotator (one of the authors of this paper) manually assessed the outputs of the models that obtained the "
    },
    {
      "expression": "\"best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " development set BLEU score as summarized in Table 56. As we can see from the bottom part of the table, all models struggle more with getting the content right than with producing linguistically correct texts; "
    },
    {
      "expression": "\"70-80%\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " of the texts generated by all models are completely correct linguistically.  Comparing the two datasets, we again observe that the WebNLG dataset is much more challenging than the E2E dataset, especially with respect to correctly verbalizing the content.  Moreover, spelling mistakes only appeared in WebNLG texts, mainly concerning omissions of accents or umlauts.  The most frequent content error in both datasets concerns omission of information.  Information addition and repetition only occur in the WebNLG dataset. The latter is an especially frequent problem of the character-based model, affecting more than "
    },
    {
      "expression": "\"a quarter\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " of all texts.  In comparison, character-based models reproduce the content more faithfully on the E2E dataset while offering the same level of linguistic quality as word-based models, leading to more correct outputs overall. On the WebNLG dataset, the word-based model is more faithful to the inputs, probably because of the effective delexicalization strategy, whereas the character-based model errs less on the linguistic side. Overall, the word-based model yields more correct texts, stressing the importance of delexicalization and data normalization in low resource settings."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen/_1810_04864v1_19"
  ],
  "datasets": ["datasets/scigen/1810.04864v1-19.json"]
}