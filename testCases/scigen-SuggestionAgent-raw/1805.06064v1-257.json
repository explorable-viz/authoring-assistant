{
    "datasets": [
        "datasets/scigen_SuggestionAgent/1805.06064v1-257.json"
    ],
    "imports": [
        "scigen",
        "util",
        "datasets/scigen_SuggestionAgent/_1805_06064v1_257"
    ],
    "variables": {},
    "testing-variables": {},
    "paragraph": [
        {
            "type": "literal",
            "value": "As expected, Table 4 shows that people with less domain knowledge are more easily deceived. Specifically, non-CS human judges fail at more than half of the 1-to-1 sets for the same titles, which suggests that most of our system generated abstracts follow correct grammar and consistent writing style. Domain experts fail on 1 or 2 sets, mostly because the human written abstracts in those sets don't seem very topically relevant. Additionally, the more abstracts that we provided to human judges, the easier it is to conceal the system generated abstract amongst human generated ones."
        }
    ]
}
