{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "The experimental results are shown in Table 1, with Int denoting internal comparisons (with three groups) and Ext denoting external comparisons, "
    },
    {
      "expression": "\"the highest\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " LAS in each group is marked in bold face. In the first group, we compare the LAS of the four single models WORD, W2V, LSTM, and CNN. In macro average of all languages, the CNN model performs "
    },
    {
      "expression": "\"higher\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than the WORD model by "
    },
    {
      "expression": "\"2.17\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "%, and "
    },
    {
      "expression": "\"higher\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than the W2V model by "
    },
    {
      "expression": "\"1.24\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "%.\nThe LSTM model, however, performs only "
    },
    {
      "expression": "\"0.9\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "% higher than the WORD model and "
    },
    {
      "expression": "\"1.27\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "% lower than the CNN model. In the second group, we observe that the additional word-lookup model does not significantly improve the CNN model (from "
    },
    {
      "expression": "\"82.75\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "% in CNN to "
    },
    {
      "expression": "\"82.90\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "% in CNN+WORD on average) while the LSTM model is improved by a much larger margin (from "
    },
    {
      "expression": "\"81.48\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "% in LSTM to "
    },
    {
      "expression": "\"82.56\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "% in LSTM+WORD on average). This suggests that the CNN model has already learned "
    },
    {
      "expression": "\"the most important\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " information from the word forms, while the LSTM model has not.\nAlso, the combined CNN+WORD model is still "
    },
    {
      "expression": "\"better\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than the LSTM+WORD model, despite the large improvement in the latter. While comparing to "
    },
    {
      "expression": "\"the best\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " published results (Bj√∂rkelund et al., 2013, 2014), we have to note that their approach uses explicit morphological features, ensemble, ranking, etc., which all can boost parsing performance. We only use a greedy parser with much fewer features, but bridge the "
    },
    {
      "expression": "\"6\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " points gap between the previous best greedy parser and "
    },
    {
      "expression": "\"the best\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " published result by more than one half.\nOn average, the B15-LSTM model improves their own baseline by "
    },
    {
      "expression": "\"1.1\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "%, similar to the "
    },
    {
      "expression": "\"0.9\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "% improvement of our LSTM model, which is much smaller than the "
    },
    {
      "expression": "\"2.17\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "% improvement of the CNN model. Furthermore, the CNN model is improved from a strong baseline: our WORD model performs already "
    },
    {
      "expression": "\"higher\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than the B15-WORD model by "
    },
    {
      "expression": "\"2.22\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "%. Comparing the individual performances on each language, we observe that the CNN model almost always outperforms the WORD model except for Hebrew. However, both LSTM and B15-LSTM perform "
    },
    {
      "expression": "\"higher\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than baseline only on the three agglutinative languages (Basque, Hungarian, and Korean), and lower than baseline on the other six."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1705_10814v1_198"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1705.10814v1-198.json"]
}
