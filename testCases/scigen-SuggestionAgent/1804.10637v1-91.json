{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Got it, I will ensure that each expression is annotated with a single category. Here's the corrected paragraph:\n\nTable "
    },
    {
      "expression": "\"2\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " shows micro F1 scores on "
    },
    {
      "expression": "\"5\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " out-domain test sets. Besides ours, only "
    },
    {
      "expression": "\"Cheng and Roth (2013)\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " employs several mention relations. Mentnorm achieves the "
    },
    {
      "expression": "\"highest\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " F1 scores on "
    },
    {
      "expression": "\"MSNBC\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and "
    },
    {
      "expression": "\"ACE2004\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". On average, ment-norm's F1 score is "
    },
    {
      "expression": "\"0.3%\"",
      "categories": ["average"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " higher than that of "
    },
    {
      "expression": "\"Ganea and Hofmann (2017)\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", but "
    },
    {
      "expression": "\"0.2%\"",
      "categories": ["min-max"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " lower than "
    },
    {
      "expression": "\"Guo and Barbosa (2016)\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "'s. It is worth noting that Guo and Barbosa (2016) performs exceptionally well on "
    },
    {
      "expression": "\"WIKI\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", but substantially "
    },
    {
      "expression": "\"worse\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "] than ment-norm on all other datasets. Our other three models, however, have "
    },
    {
      "expression": "\"lower\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " average F1 scores compared to the "
    },
    {
      "expression": "\"best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " previous model. The experimental results show that ment-norm outperforms "
    },
    {
      "expression": "\"rel-norm\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", and that mention padding plays an important role."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1804_10637v1_91"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1804.10637v1-91.json"]
}