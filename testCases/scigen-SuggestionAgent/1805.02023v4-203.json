{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "As shown in Table 4, without using word segmentation, a "
    },
    {
      "expression": "\"characterbased LSTM-CRF\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " model gives a development F1score of "
    },
    {
      "expression": "\"62.47%\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". Adding "
    },
    {
      "expression": "\"character-bigram and softword representations\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " as described in Section 3.1 increases the F1-score to "
    },
    {
      "expression": "\"67.63%\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and "
    },
    {
      "expression": "\"65.71%\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", respectively, demonstrating the usefulness of both sources of information. In addition, a combination of both gives a "
    },
    {
      "expression": "\"69.64%\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " F1-score, which is "
    },
    {
      "expression": "\"the best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " among various character representations.  Table 4 shows a variety of different settings for "
    },
    {
      "expression": "\"word-based Chinese NER\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". With automatic segmentation, a "
    },
    {
      "expression": "\"word-based LSTM CRF baseline\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " gives a "
    },
    {
      "expression": "\"64.12%\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " F1-score, which is "
    },
    {
      "expression": "\"higher\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " compared to the character-based baseline. This demonstrates that both word information and character information are useful for Chinese NER. The two methods of  "
    },
    {
      "expression": "\"word+char LSTM\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and "
    },
    {
      "expression": "\"word+char LSTM(cid:48)\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", lead to similar improvements.  A "
    },
    {
      "expression": "\"CNN representation of character sequences\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " gives a slightly "
    },
    {
      "expression": "\"higher\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " F1-score compared to "
    },
    {
      "expression": "\"LSTM character representations\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". On the other hand, further using character bigram information leads to increased F1-score over "
    },
    {
      "expression": "\"word+char LSTM\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", but decreased F1-score over "
    },
    {
      "expression": "\"word+char CNN\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ".  As shown in Table 4, the "
    },
    {
      "expression": "\"lattice LSTM-CRF\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " model gives a development F1-score of "
    },
    {
      "expression": "\"71.62%\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", which is significantly"
    },
    {
      "expression": "\"higher\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "] compared with both the word-based and character-based methods, despite that it does not use character bigrams or word segmentation information."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1805_02023v4_203"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1805.02023v4-203.json"]
}