{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "As shown in "
    },
    {
      "expression": "\"Table 3\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", "
    },
    {
      "expression": "\"BiLSTM\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " gives "
    },
    {
      "expression": "\"significantly better accuracies\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " compared to "
    },
    {
      "expression": "\"uni-directional LSTM2\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", with the training time per epoch growing from "
    },
    {
      "expression": "\"67 seconds\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " to "
    },
    {
      "expression": "\"106 seconds\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". Stacking 2 layers of BiLSTM gives further improvements to development results, with a larger time of "
    },
    {
      "expression": "\"207 seconds\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". "
    },
    {
      "expression": "\"3 layers\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " of stacked BiLSTM does not further improve the results. In contrast, "
    },
    {
      "expression": "\"S-LSTM\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " gives a development result of "
    },
    {
      "expression": "\"82.64%\"",
      "categories": ["min-max"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", which is "
    },
    {
      "expression": "\"significantly better\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " compared to "
    },
    {
      "expression": "\"2-layer stacked BiLSTM\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", with a smaller number of model parameters and a shorter time of "
    },
    {
      "expression": "\"65 seconds\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". We additionally make comparisons with stacked CNNs and hierarchical attention ("
    },
    {
      "expression": "\"Vaswani et al., 2017\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "), shown in "
    },
    {
      "expression": "\"Table 3\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " (the CNN and Transformer rows), "
    },
    {
      "expression": "\"CNN\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " is the most efficient among all models compared, with the smallest model size. On the other hand, a "
    },
    {
      "expression": "\"3-layer stacked CNN\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " gives an accuracy of "
    },
    {
      "expression": "\"81.46%\"",
      "categories": ["min-max"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", which is also "
    },
    {
      "expression": "\"the lowest\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " compared with BiLSTM, hierarchical attention and S-LSTM. The "
    },
    {
      "expression": "\"best performance\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " of hierarchical attention is between single-layer and two-layer BiLSTMs in terms of both accuracy and efficiency. "
    },
    {
      "expression": "\"S-LSTM\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " gives "
    },
    {
      "expression": "\"significantly better accuracies\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " compared with both CNN and hierarchical attention. "
    },
    {
      "expression": "\"Table 3\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " additionally shows the results of BiLSTM and S-LSTM when external attention is used Attention leads to improved accuracies for both BiLSTM and S-LSTM in classification, with S-LSTM still outperforming BiLSTM significantly."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen/_1805_02474v1_10"
  ],
  "datasets": ["datasets/scigen/1805.02474v1-10.json"]
}