{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "The results of unimodal sentiment prediction experiments are shown in Table 2.  The verbal models have "
    },
    {
      "expression": "\"the best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " performance here,  On each modality, "
    },
    {
      "expression": "\"the best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " performance is achieved by a "
    },
    {
      "expression": "\"multi-task learning model\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ".  All unimodal models have significantly "
    },
    {
      "expression": "\"different\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " performance. p = "
    },
    {
      "expression": "\"0.009\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " for S+P and S+P+I Visual models, p << "
    },
    {
      "expression": "\"0.001\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " for Visual and Vocal S+I models.  In multi-task learning, the main task gains additional information from the auxillary tasks. Compared to the S model, the S+P model has increased focus on the polarity of sentiment, while the S+I model has increased focus on the intensity of sentiment. On the verbal modality, the "
    },
    {
      "expression": "\"S+P\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " model achieved "
    },
    {
      "expression": "\"the best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " performance, while on the visual modality the "
    },
    {
      "expression": "\"S+I\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " model achieved "
    },
    {
      "expression": "\"the best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " performance.  For the vocal modality, the "
    },
    {
      "expression": "\"S+P+I\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " model achieved "
    },
    {
      "expression": "\"the best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " performance, and the S+P model yielded improved performance over that of the S model."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1807_01466v1_258"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1807.01466v1-258.json"]
}