{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Table 2 shows that initializing the model with "
    },
    {
      "expression": "\"the pre-trained embeddings\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " gives a significant "
    },
    {
      "expression": "\"4.11\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " point increase in F-measure compared to "
    },
    {
      "expression": "\"random initialization\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", due to an increase in precision. Fixing the embeddings gives slightly "
    },
    {
      "expression": "\"better\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " performance than using them as initialization, an increase of "
    },
    {
      "expression": "\"0.9\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " point in F-measure, mostly due to "
    },
    {
      "expression": "\"higher\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " recall. When extending the loss with the "
    },
    {
      "expression": "\"SGLR loss\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", we gain"
    },
    {
      "expression": "\"1.6\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " in F-measure compared to fixing the word embeddings, and also surpass the state of the art by "
    },
    {
      "expression": "\"0.4\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " even without specialized resources. If we train our model using the SG loss extension we obtain "
    },
    {
      "expression": "\"the best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " results, and gain"
    },
    {
      "expression": "\"1.9\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " points in F-measure compared to using pre-trained fixed word embeddings. This setting also exceeds the state of the art (Lin et al., 2017) by "
    },
    {
      "expression": "\"0.7\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " points in F-measure, due to a gain of "
    },
    {
      "expression": "\"1.2\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " points in recall, again without using any specialized clinical NLP tools for feature engineering, in contrast to all state-of-the-art baselines."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1808_02374v1_74"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1808.02374v1-74.json"]
}