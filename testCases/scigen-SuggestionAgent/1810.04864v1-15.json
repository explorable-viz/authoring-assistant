{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Table 2 and 3 display the results on the E2E and WebNLG test sets for models of the respective challenges and our own models. On the E2E test set, our single "
    },
    {
      "expression": "\"best\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " word- and character-based models reach "
    },
    {
      "expression": "\"comparable\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " results to "
    },
    {
      "expression": "\"the best\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " challenge submissions. The word-based models achieve "
    },
    {
      "expression": "\"significantly higher\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " BLEU and ROUGE-L scores than the character-based models."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1810_04864v1_15"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1810.04864v1-15.json"]
}
