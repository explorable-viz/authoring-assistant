{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "One annotator (one of the authors of this paper) manually assessed the outputs of the models that obtained "
    },
    {
      "expression": "\"the best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " development set BLEU score as summarized in Table 56. As we can see from the bottom part of the table, all models struggle more with getting the content right than with producing linguistically correct texts; "
    },
    {
      "expression": "\"70-80%\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " of the texts generated by all models are completely correct linguistically.  Comparing the two datasets, we again observe that the "
    },
    {
      "expression": "\"WebNLG\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " dataset is much more challenging than the "
    },
    {
      "expression": "\"E2E\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " dataset, especially with respect to correctly verbalizing the content.  Moreover, spelling mistakes only appeared in "
    },
    {
      "expression": "\"WebNLG\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " texts, mainly concerning omissions of accents or umlauts.  The most frequent content error in both datasets concerns omission of information.  Information addition and repetition only occur in the "
    },
    {
      "expression": "\"WebNLG\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " dataset. The latter is an especially frequent problem of the character-based model, affecting "
    },
    {
      "expression": "\"more than a quarter\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " of all texts.  In comparison, character-based models reproduce the content more faithfully on the "
    },
    {
      "expression": "\"E2E\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " dataset while offering the same level of linguistic quality as word-based models, leading to "
    },
    {
      "expression": "\"more correct\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "] outputs overall. On the "
    },
    {
      "expression": "\"WebNLG\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " dataset, the word-based model is more faithful to the inputs, probably because of the effective delexicalization strategy, whereas the character-based model errs less on the linguistic side. Overall, the word-based model yields "
    },
    {
      "expression": "\"more correct\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "] texts, stressing the importance of delexicalization and data normalization in low resource settings."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1810_04864v1_19"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1810.04864v1-19.json"]
}