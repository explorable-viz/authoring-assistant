{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "I apologize for the mistake. I will ensure to use only one category per annotation as specified. Here is the corrected version:\n\nTables 2 and 3 respectively show results for our pretraining and intermediate training experiments. Looking to Table 3, using "
    },
    {
      "expression": "\"ELMo\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " uniformly improves over training the encoder from scratch. The "
    },
    {
      "expression": "\"ELMo-augmented random baseline\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " is strong, lagging behind the "
    },
    {
      "expression": "\"single-task baseline\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " by "
    },
    {
      "expression": "\"less than a point\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". Most intermediate tasks beat the "
    },
    {
      "expression": "\"random baseline\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", but several fail to significantly outperform the "
    },
    {
      "expression": "\"single-task baseline\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". "
    },
    {
      "expression": "\"MNLI\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and "
    },
    {
      "expression": "\"English\u2013German translation\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " perform "
    },
    {
      "expression": "\"best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " with "
    },
    {
      "expression": "\"ELMo\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", with "
    },
    {
      "expression": "\"SkipThought\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and "
    },
    {
      "expression": "\"DisSent\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " also beating the "
    },
    {
      "expression": "\"single-task baseline\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". Intermediate multitask training on all the non-GLUE tasks produces our "
    },
    {
      "expression": "\"best-performing ELMo model\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". Using "
    },
    {
      "expression": "\"BERT\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " consistently outperforms "
    },
    {
      "expression": "\"ELMo\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and pretraining from scratch. We find that intermediate training on each of "
    },
    {
      "expression": "\"MNLI\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", "
    },
    {
      "expression": "\"QQP\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", and "
    },
    {
      "expression": "\"STS\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " leads to improvements over no intermediate training, while intermediate training on the other tasks harms transfer performance. The "
    },
    {
      "expression": "\"improvements gained via STS\"",
      "categories": ["average"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " , a small-data task, versus the negative impact of fairly large-data tasks (e.g. "
    },
    {
      "expression": "\"QNLI\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "), suggests that the benefit of intermediate training is not solely due to additional training, but that the signal provided by the intermediate task complements the original language modeling objective. Intermediate training on generation tasks such as "
    },
    {
      "expression": "\"MT\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and "
    },
    {
      "expression": "\"SkipThought\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " significantly impairs "
    },
    {
      "expression": "\"BERT's transfer ability\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". We speculate that this degradation may be due to catastrophic forgetting in fine-tuning for a task substantially different from the tasks "
    },
    {
      "expression": "\"BERT\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " was originally trained on. This phenomenon might be mitigated in our "
    },
    {
      "expression": "\"ELMo models\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " via the frozen encoder and skip connection. On the test set, we lag slightly behind the "
    },
    {
      "expression": "\"BERT base results\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " from Devlin et al. (2019), likely due in part to our limited hyperparameter tuning."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1812_10860v5_194"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1812.10860v5-194.json"]
}