{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "We present sample generations, quality results, and diversity results respectively in Tables 1, 2, 3.  This observation is further bolstered by the fact that the GPT generations have a "
    },
    {
      "expression": "\"higher\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " corpus-BLEU with TBC than TBC has with itself.  The corpusBLEU between BERT models and the datasets is low, particularly with WT103.  We find that BERT generations are "
    },
    {
      "expression": "\"more diverse\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than GPT generations. GPT has "
    },
    {
      "expression": "\"high\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " n-gram overlap (smaller percent of unique n-grams) with TBC, but surprisingly also with WikiText-103, despite being trained on different data. Furthermore, GPT generations have "
    },
    {
      "expression": "\"greater\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " n-gram overlap with these datasets than these datasets have with themselves, further suggesting that GPT is relying significantly on generic sentences. BERT has lower n-gram overlap with both corpora, with similar degrees of n-gram overlap as the samples of the data."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1902_04094v2_184"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1902.04094v2-184.json"]
}
