{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Got it, I will ensure to use the correct categories as per your instructions. Here's the corrected output:\n\nParagraph:\nFor NER (Table 7), S-LSTM gives an F1-score of 91.57% on the CoNLL test set, which is significantly\r\nbetter compared with BiLSTMs. The minimum F1-score was obtained by BiLSTM.\r\nThe average training time of the BiLSTM-small variants is 1.7 hours\r\nwhile the total training time required to run all the models is 28.5 hours.\r\nStacking more layers of BiLSTMs leads to slightly better F1-scores\r\ncompared with a single-layer BiLSTM. Our BiLSTM results are comparable to the results reported\r\nby Ma and Hovy (2016) and Lample et al. (2016).\r\nIn contrast, S-LSTM gives the best reported results under the same settings.\r\nIn the second section of Table 7, Yang et al. (2017) obtain an Fscore of 91.26%.\r\n\r\nData:\r\nData: [\r\n  {model: \"BiLSTM\", accuracy: 90.3, params_M: 6.8, train_time_h: 3.2, memory_GB: 1.1},\r\n  {model: \"2 stacked BiLSTM\", accuracy: 91.0, params_M: 9.1, train_time_h: 4.5, memory_GB: 1.6},\r\n  {model: \"3 stacked BiLSTM\", accuracy: 91.2, params_M: 11.4, train_time_h: 5.9, memory_GB: 2.0},\r\n  {model: \"S-LSTM\", accuracy: 92.4, params_M: 7.9, train_time_h: 3.8, memory_GB: 1.3},\r\n  {model: \"yang2017transfer\", accuracy: 91.1, params_M: 10.2, train_time_h: 6.0, memory_GB: 2.2},\r\n  {model: \"BiLSTM-small-1\", accuracy: 88.2, params_M: 3.4, train_time_h: 1.6, memory_GB: 0.7},\r\n  {model: \"BiLSTM-small-2\", accuracy: 88.6, params_M: 3.5, train_time_h: 1.7, memory_GB: 0.7},\r\n  {model: \"BiLSTM-small-3\", accuracy: 89.1, params_M: 3.6, train_time_h: 1.8, memory_GB: 0.8}\r\n]\r\n\r\n\r\nOutput:\nFor NER (Table 7), "
    },
    {
      "expression": "\"S-LSTM\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " gives an F1-score of "
    },
    {
      "expression": "\"91.57%\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " on the CoNLL test set, which is significantly\r\n"
    },
    {
      "expression": "\"better\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " compared with "
    },
    {
      "expression": "\"BiLSTMs\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". The "
    },
    {
      "expression": "\"minimum\"",
      "categories": ["min-max"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " F1-score was obtained by "
    },
    {
      "expression": "\"BiLSTM\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ".\r\nThe "
    },
    {
      "expression": "\"average\"",
      "categories": ["average"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " training time of the "
    },
    {
      "expression": "\"BiLSTM-small\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " variants is "
    },
    {
      "expression": "\"1.7 hours\"",
      "categories": ["average"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "\r\nwhile the "
    },
    {
      "expression": "\"total\"",
      "categories": ["sum"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " training time required to run all the models is "
    },
    {
      "expression": "\"28.5 hours\"",
      "categories": ["sum"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ".\r\nStacking more layers of BiLSTMs leads to slightly "
    },
    {
      "expression": "\"better\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " F1-scores\r\ncompared with a single-layer "
    },
    {
      "expression": "\"BiLSTM\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". Our "
    },
    {
      "expression": "\"BiLSTM\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " results are comparable to the results reported\r\nby Ma and Hovy (2016) and Lample et al. (2016).\r\nIn contrast, "
    },
    {
      "expression": "\"S-LSTM\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " gives the "
    },
    {
      "expression": "\"best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " reported results under the same settings.\r\nIn the second section of Table 7, Yang et al. (2017) obtain an Fscore of "
    },
    {
      "expression": "\"91.26%\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1902_04094v2_184"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1902.04094v2-184.json"]
}