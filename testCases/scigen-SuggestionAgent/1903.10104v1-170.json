{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Thank you for the clarification. Here is the corrected paragraph with the appropriate category:\n\nF1 scores for all propositions and each type are reported in Table 5.  "
    },
    {
      "expression": "\"CNN\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " performs "
    },
    {
      "expression": "\"better\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " for types with significantly more training samples, i.e., "
    },
    {
      "expression": "\"evaluation\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and "
    },
    {
      "expression": "\"fact\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", indicating the effect of data size on neural model's performance. "
    },
    {
      "expression": "\"Joint models (CRF-joint and BiLSTM-CRF-joint)\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " yield the "
    },
    {
      "expression": "\"best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " F1 scores for all categories when gold-standard segmentation is unavailable."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1903_10104v1_170"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1903.10104v1-170.json"]
}