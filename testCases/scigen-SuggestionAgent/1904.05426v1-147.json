{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Likewise, the utility of "
    },
    {
      "expression": "\"CIPHER-AVG\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " tags for dependency parsing under zero-resource scenarios is summarized in Table 4 and Table 5.  We then take the next logical step and remove the parallel data-grounded embeddings, replacing them with fully unsupervised MUSE embeddings. "
    },
    {
      "expression": "\"Table 5\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " summarizes these results.  It can be observed that POS signal improves performance greatly for all languages when using MUSE embeddings.  Here we note a mixed result: whilst "
    },
    {
      "expression": "\"de, sv, and it\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " do benefit from POS information, the other languages do not, obtaining great improvements from MUSE embeddings instead.  Finally, consider "
    },
    {
      "expression": "\"MUSE-CIPHER (gold POS tags during training, cipher tags during testing)\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". When compared to "
    },
    {
      "expression": "\"MUSE-NONE\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " setup, it can be observed that, unfortunately, the heuristic POS tagger is too noisy and gets in MUSE's way."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen/_1904_05426v1_147"
  ],
  "datasets": ["datasets/scigen/1904.05426v1-147.json"]
}