{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Table 4 also contains results that use only the explanation and exclude the original question from CQA denoted by 'w/o question'. These variants also use explanation during both train and validation. We observe that even using these limited kind of explanations improves "
    },
    {
      "expression": "\"over\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "] the "
    },
    {
      "expression": "\"BERT baseline\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " in Table 4, which suggests that the explanations are providing useful information beyond just mentioning the correct or incorrect answers. In Table 2, using CAGE-reasoning at both train and validation resulted in an accuracy of "
    },
    {
      "expression": "\"72%\"",
      "categories": ["ratio"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", but Table 4 shows that if CAGE-reasoning truly captured all information provided in CoS-E-openended, performance would be "
    },
    {
      "expression": "\"90%\"",
      "categories": ["ratio"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1906_02361v1_396"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1906.02361v1-396.json"]
}