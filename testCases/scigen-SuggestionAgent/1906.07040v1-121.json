{
  "testing-variables": {},
  "paragraph": [{
    "type": "literal",
    "value": "Discussion of Results Table 2 presents the WSD micro-F1 scores using raw WordNet similarities, 300D path2vec, DeepWalk and node2vec models, and the 128D FSE model. We evaluate on the following all-words English WSD test sets:  Senseval-2 (Palmer et al., 2001), Senseval-3 (Mihalcea et al., 2004), and SemEval-15 Task 13 (Moro and Navigli, 2015). The raw WordNet similarities have a small edge over their vector approximations in the majority of the cases yet the path2vec models consistently closely follow them while outperforming other graph embedding baselines: We indicate the differences with respect to the original with a subscript number."
  }],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1906_07040v1_121"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1906.07040v1-121.json"]
}