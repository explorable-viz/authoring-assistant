{
  "testing-variables": {},
  "paragraph": [{
    "type": "literal",
    "value": "We conduct transfer learning on four different combinations of MedNLI, SNLI, and MNLI as it shown in the table 4 (line 4 to 7) and also add the results of general domain tasks (MNLI, SNLI) for comparison.  BERT performs better on tasks in the general domain while BioBERT performs better on MedNLI which is in the clinical domain.  positive transfer occurs on MedNLI.  even though BioBERT is finetuned on general domain tasks before MedNLI, transfer learning shows better results than that fine-tuned on MedNLI directly.  the domain specific language representations from BioBERT are maintained while fine-tuning on general domain tasks by showing that the transfer learning results of MedNLI on BioBERT have better performance than the results on BERT (line 4 to 7).  the accuracy of MNLI and SNLI on BioBERT is lower than the accuracy on BERT.  The best combination is SNLI → MNLI → MedNLI on BioBERT.  MedNLI (expanded) shows better performance than MedNLI on BioBERT while MedNLI works better on BERT (see table 4).  the performance of MedNLI (expanded) with transfer learning is higher on BERT and lower on BioBERT than the performance of MedNLI with transfer learning."
  }],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen/_1906_07854v1_1"
  ],
  "datasets": ["datasets/scigen/1906.07854v1-1.json"]
}