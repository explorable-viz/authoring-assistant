{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "I understand now. I will ensure that each annotation uses only one of the specified valid categories.\n\nHere is the corrected paragraph:\n\nTable 1 (upper part) shows the results of our basic semantic parser ("
    },
    {
      "expression": "\"GloVe\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " embeddings) on all "
    },
    {
      "expression": "\"six\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " graphbanks. Our results are competitive across the board, and set a new state of the art for "
    },
    {
      "expression": "\"EDS\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " Smatch scores ("
    },
    {
      "expression": "\"Cai\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and "
    },
    {
      "expression": "\"Knight\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", 2013) among "
    },
    {
      "expression": "\"EDS parsers\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " which are not trained on gold syntax information. Our EDM score ("
    },
    {
      "expression": "\"Dridan\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and "
    },
    {
      "expression": "\"Oepen\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", 2011) on "
    },
    {
      "expression": "\"EDS\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " is "
    },
    {
      "expression": "\"lower\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". The use of BERT embeddings is highly effective across the board. We set a new state of the art on all graphbanks except "
    },
    {
      "expression": "\"AMR 2017\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "; The improvement is particularly pronounced in the out-of-domain evaluations, illustrating BERT's ability to transfer across domains. The results on the test dataset are shown in Table 1 (bottom). With GloVe, multi-task learning led to substantial improvements; with BERT the improvements are smaller but still noticeable.\n\nIn this version, \"lower\" is annotated with only the `COMPARISON` category and \"AMR 2017\" is annotated with only the `DATA_RETRIEVAL` category."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1906_11746v2_0"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1906.11746v2-0.json"]
}