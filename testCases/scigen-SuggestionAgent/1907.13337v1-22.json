{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "The automatic evaluation scores are presented in Table 1 and Table 2. Our method outperforms commonly used prefix baselines for this task which take the first 75 characters or 8 words of the source as a summary. Our system achieves "
    },
    {
      "expression": "\"comparable\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " results to Wang and Lee (2018) a system based on both GANs and reinforcement training. In Table 1, we also list scores of the state-of-the-art supervised model, an attention based seq-to-seq model of our own implementation, as well as the oracle scores of our method obtained by choosing "
    },
    {
      "expression": "\"the best\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " summary among all finished hypothesis from beam search. The oracle scores are "
    },
    {
      "expression": "\"much higher\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", indicating that our unsupervised method does allow summaries of "
    },
    {
      "expression": "\"better\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " quality,"
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigenCL/_1907_13337v1_22"
  ],
  "datasets": ["datasets/scigenCL/1907.13337v1-22.json"]
}