{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "The automatic evaluation scores are presented in Table 1 and Table 2. Our method outperforms commonly used prefix baselines for this task which take the first "
    },
    {
      "expression": "\"75 characters\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " or "
    },
    {
      "expression": "\"8 words\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " of the source as a summary. Our system achieves comparable results to Wang and Lee (2018) a system based on both GANs and reinforcement training. In Table 1, we also list scores of the state-of-the-art supervised model, an attention based seq-to-seq model of our own implementation, as well as the oracle scores of our method obtained by choosing "
    },
    {
      "expression": "\"the best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " summary among all finished hypothesis from beam search. The oracle scores are "
    },
    {
      "expression": "\"much higher\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", indicating that our unsupervised method does allow summaries of "
    },
    {
      "expression": "\"better quality\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1907_13337v1_22"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1907.13337v1-22.json"]
}