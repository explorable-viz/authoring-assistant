{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "In Table 2, we compare the development set results of "
    },
    {
      "expression": "\"the state of the art\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " methods with the BERT model trained on different retrieved evidence sets. The BERT claim verification system even if it is trained on the UKP-Athene sentence retrieval component (Hanselowski et al., 2018), "
    },
    {
      "expression": "\"the state of the art method with the highest recall\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", improves both label accuracy and FEVER score. Training based on the BERT sentence retrieval predictions significantly enhances the verification results because while it explicitly improves the FEVER score by providing more correct evidence sentences, it provides "
    },
    {
      "expression": "\"better\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " training set for the verification system. The large BERTs are only trained on "
    },
    {
      "expression": "\"the best\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " retrieval systems, and as expected significantly improve the performance."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigenCL/_1910_02655v1_351"
  ],
  "datasets": ["datasets/scigenCL/1910.02655v1-351.json"]
}