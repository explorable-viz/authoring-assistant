{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "In Table 2, we compare the development set results of the state of the art methods with the "
    },
    {
      "expression": "\"BERT\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " model trained on different retrieved evidence sets. The "
    },
    {
      "expression": "\"BERT\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " claim verification system even if it is trained on the UKP-Athene sentence retrieval component (Hanselowski et al., 2018), the state of the art method with the "
    },
    {
      "expression": "\"highest recall\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", improves both label accuracy and FEVER score. Training based on the BERT sentence retrieval predictions significantly enhances the verification results because while it explicitly improves the FEVER score by providing more correct evidence sentences, it provides a better training set for the verification system. The large "
    },
    {
      "expression": "\"BERTs\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " are only trained on the "
    },
    {
      "expression": "\"best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " retrieval systems, and as expected significantly improve the performance."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1910_02655v1_351"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1910.02655v1-351.json"]
}