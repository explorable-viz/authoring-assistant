{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "A sample of the SQuAD v1.1 test set (only the first paragraph of each of the "
    },
    {
      "expression": "\"48\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " Wikipedia pages) has been translated by humans in French and Japanese. We here evaluate the performance of the fine-tuned multilingual BERT on them and compare the results to a baseline .  Table 1 displays the Exact Match (EM) and F1-score of the "
    },
    {
      "expression": "\"baseline\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and multilingual "
    },
    {
      "expression": "\"BERT\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " on the selected datasets. We can observe that multilingual BERT is able to significantly outperform the baseline on both the "
    },
    {
      "expression": "\"Japanese\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and the "
    },
    {
      "expression": "\"French\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " question answering task.  was already noted in the public benchmarks and we add here that BERT has a high ability for QA zero-shot transfer. It is even able to significantly outperform the baseline"
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1910_04659v1_349"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1910.04659v1-349.json"]
}