{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "The model has relatively low accuracy on the entailment and contradiction examples while "
    },
    {
      "expression": "\"close to zero\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " accuracy on the neutral ones. The accuracy of the model on each test set. On our dative alternation dataset, the accuracy on our test sets is "
    },
    {
      "expression": "\"substantially lower than\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " on the MultiNLI development set ("
    },
    {
      "expression": "\"50.78\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "% versus "
    },
    {
      "expression": "\"84.66%\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " respectively), The model has very high accuracy on the entailment examples, while "
    },
    {
      "expression": "\"close to zero\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " on the contradiction ones. On the numerical reasoning dataset, the model also seems to fail on this inference type with test set accuracy "
    },
    {
      "expression": "\"much lower than\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " on the MultiNLI development set,"
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1910_09302v1_224"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1910.09302v1-224.json"]
}
