{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "The final model used the finetuned BERT model mentioned above with a condition to predict non-propaganda only if the prediction probability is above "
    },
    {
      "expression": "\"0.70\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " for the nonpropaganda class. Otherwise the prediction of the sentence will be propaganda even if the majority of the prediction probability mass was for the non-propaganda class. This was a way to handle the unbalance in the training data without having to discard part of the data. The "
    },
    {
      "expression": "\"0.70\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " threshold was chosen after elaborate experiments on both the local and the shared-task's development sets. This condition consistently provided an improvement of around "
    },
    {
      "expression": "\"5 points\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " in F1 score of the propaganda class on all experiments using different sets of features as shown in Table 2. In SLC, we ran multiple experiments using BERT with and without additional features as shown in Table 2. The features include using the text passed as is to BERT without any preprocessing. Also, we experimented with adding the context which includes the two sentences that come before and after the target sentence. Context sentences were concatenated and passed as the second BERT input, while the target sentence was passed as the first BERT input. In addition, we experimented with using BERT logits (i.e., the probability predictions per class) as features in a Logistic Regression (LR) classifier concatenated with handcrafted features (e.g., LIWC, quotes, questions), and with predictions of our FLC classifier (tagged spans: whether the sentence has a propaganda fragment or not). However, none of these features added any statistically significant improvements. Therefore, we used BERT predictions for our final model with a condition to predict the majority class non-propaganda only if its prediction probability is "
    },
    {
      "expression": "\"more than\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " "
    },
    {
      "expression": "\"0.70\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " as shown in Table 3. This is a modified threshold as opposed to "
    },
    {
      "expression": "\"0.80\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " in the experiments shown in Table 2 to avoid overfitting on a one dataset. The final threshold of "
    },
    {
      "expression": "\"0.70\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " was chosen after experiments on both the local and shared task development sets, which also represents the ratio of the non-propaganda class in the training set."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1910_09702v1_466"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1910.09702v1-466.json"]
}
