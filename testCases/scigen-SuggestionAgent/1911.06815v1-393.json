{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "The left side of "
    },
    {
      "expression": "\"Table 1\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " shows the performance for the "
    },
    {
      "expression": "\"three baselines\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and for our multi-granularity network on the "
    },
    {
      "expression": "\"FLC task\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ".  "
    },
    {
      "expression": "\"Table 1\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " (right) shows that using additional information from the sentence-level for the token-level classification ("
    },
    {
      "expression": "\"BERT-Granularity\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ") yields small improvements. The multi-granularity models outperform all baselines thanks to their "
    },
    {
      "expression": "\"higher precision\"",
      "categories": ["min-max"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". This shows the effect of the model excluding sentences that it determined to be non-propagandistic from being considered for token-level classification.  The right side of "
    },
    {
      "expression": "\"Table 1\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " shows the results for the "
    },
    {
      "expression": "\"SLC task\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". We apply our multi-granularity network model to the sentence-level classification task to see its effect on low granularity when we train the model with a high granularity task. Interestingly, it yields huge performance improvements on the sentence-level classification result. Compared to the "
    },
    {
      "expression": "\"BERT\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " baseline, it increases the recall by "
    },
    {
      "expression": "\"8.42\"",
      "categories": ["ratio"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "%, resulting in a "
    },
    {
      "expression": "\"3.24\"",
      "categories": ["ratio"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "% increase of the F1 score."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1911_06815v1_393"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1911.06815v1-393.json"]
}