{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "We present the test results in Table 2. We are able to reproduce the performance of the baseline model (\"CNN w/ GloVe\"), and find that once again, adding the shallow discourse features improves results. Interestingly, we found that replacing the CNN with an LSTM results in improved MAE, but "
    },
    {
      "expression": "\"worse\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " MAPE. Adding discourse features to this model generally has marginal improvement in all cases. When we replace the word sequence with EDUs (\"Bi-LSTM w/ latent\" and \"Bi-LSTM w/ shallow\"), we see that the latent features outperform "
    },
    {
      "expression": "\"the shallow\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " features."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_1911_06919v1_311"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/1911.06919v1-311.json"]
}
