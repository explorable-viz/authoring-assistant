{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "The experimental results are shown in Table 1. As "
    },
    {
      "expression": "\"Keller\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " is created based on the "
    },
    {
      "expression": "\"PP distribution\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and have relatively small size while "
    },
    {
      "expression": "\"SP-10K\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " is created based on random sampling and has a much larger size, we treat the performance on "
    },
    {
      "expression": "\"SP-10K\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " as the major evaluation. Our embeddings significantly outperform other baselines, especially embedding based baselines. The only exception is "
    },
    {
      "expression": "\"PP\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " on the "
    },
    {
      "expression": "\"Keller\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " dataset due to its biased distribution. In addition, there are other interesting observations. First, compared with '"
    },
    {
      "expression": "\"'dobj'\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "' and '"
    },
    {
      "expression": "\"'nsubj'\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "', '"
    },
    {
      "expression": "\"'amod'\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "' is simpler for "
    },
    {
      "expression": "\"word2vec\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and "
    },
    {
      "expression": "\"GloVe\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". The reason behind is that conventional embeddings only capture the co-occurrence information, which is enough to predict the selectional preference of"
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_2001_02836v1_130"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/2001.02836v1-130.json"]
}