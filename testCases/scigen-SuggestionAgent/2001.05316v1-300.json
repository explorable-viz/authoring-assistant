{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Various subsets of authors were chosen and the dataset was truncated to each author having the same number of samples. With and without "
    },
    {
      "expression": "\"pre-trained\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " character level embedding and comparing the proposed architectures on the held-out dataset. To illustrate the need of "
    },
    {
      "expression": "\"pre-trained\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " character embeddings, we see from III that using a "
    },
    {
      "expression": "\"pre-trained\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " embedding increases the accuracy across datasets and the different number of authors, regardless of the amount of data for each author. Increase the performance a few degrees. We analyzed the importance of "
    },
    {
      "expression": "\"pre-trained\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " character embedding for author attribution and showed that pre-training can result in "
    },
    {
      "expression": "\"better\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " performances."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_2001_05316v1_300"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/2001.05316v1-300.json"]
}
