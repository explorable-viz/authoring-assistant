{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "The experiment results are presented in Table 2. The "
    },
    {
      "expression": "\"best performances\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " of our configurations are highlighted in red, which are "
    },
    {
      "expression": "\"8.37\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", "
    },
    {
      "expression": "\"3.67\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", "
    },
    {
      "expression": "\"13.79\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and "
    },
    {
      "expression": "\"7.89\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " for the error rates of our proposed model on "
    },
    {
      "expression": "\"AG\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", "
    },
    {
      "expression": "\"Sogou\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", "
    },
    {
      "expression": "\"AG(5k)\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", "
    },
    {
      "expression": "\"Sogou(10k)\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " respectively. The bold numbers are the officially reported accuracy of "
    },
    {
      "expression": "\"VDCNN\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", to which our proposed model is close. The numbers in blue are the results coming from our comparison experiment by using "
    },
    {
      "expression": "\"VDCNN\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " where we set the sequence length to "
    },
    {
      "expression": "\"256\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " under word level. From these results we can see that our model outperforms "
    },
    {
      "expression": "\"VDCNN\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " on "
    },
    {
      "expression": "\"AG News\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " for the official error rate, and is very close to "
    },
    {
      "expression": "\"VDCNN's\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " performance on "
    },
    {
      "expression": "\"Sogou News\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". If we set "
    },
    {
      "expression": "\"VCDNN\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " with the same input sequence length ("
    },
    {
      "expression": "\"256\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ") in word-level, the performance of our proposed model is obviously "
    },
    {
      "expression": "\"better\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ".  Most of the contributions come from external matrix From the results of Table 2, in the case of training with a large scale dataset, no matter we use simple "
    },
    {
      "expression": "\"LSTM\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " or more complex bi-directional "
    },
    {
      "expression": "\"LSTM\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " with self-attention, the testing error rates of different configurations are basically similar to each other. It can be said that such near state-of-the-art performance mainly attributes to the contribution from external memory.  Using abstract to build the external memory is better than contents  From Table 2 we can see that the results of using the description to construct the semantics matrix are "
    },
    {
      "expression": "\"better\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than using the abstract.  SeMemNN can still work on a few-shot learning Table 2 shows that although we have greatly shrank the scale of the training set, our proposed method can still outperform "
    },
    {
      "expression": "\"VDCNN\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". After shrinking the scale of the data, the performance of "
    },
    {
      "expression": "\"VDCNN\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " has been greatly decreased, especially for "
    },
    {
      "expression": "\"Sogou news\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", "
    },
    {
      "expression": "\"VDCNN\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " has been unable to learn from the training samples."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_2003_01857v1_420"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/2003.01857v1-420.json"]
}