{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Our results for citation needed detection are given in Table 1. The vanilla "
    },
    {
      "expression": "\"BERT\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " model already significantly outperforms the state of the art "
    },
    {
      "expression": "\"model from Redi et al. (2019)\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " (a "
    },
    {
      "expression": "\"GRU network with global attention\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ") by "
    },
    {
      "expression": "\"6\"",
      "categories": ["difference"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " F1 points. We saw further gains in performance with "
    },
    {
      "expression": "\"PU learning\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", as well as when using "
    },
    {
      "expression": "\"PUC\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". Additionally, the models using "
    },
    {
      "expression": "\"PU learning\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " had "
    },
    {
      "expression": "\"lower\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " variance, indicating more consistent performance across runs. The "
    },
    {
      "expression": "\"best performing model\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " we saw was the one trained using "
    },
    {
      "expression": "\"PUC\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " with an F1 score of "
    },
    {
      "expression": "\"0.826\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_2003_02736v1_398"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/2003.02736v1-398.json"]
}