{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Cross-lingual transfer is powerful (RQ1). Zero-shot learning reaches an F1 score of "
    },
    {
      "expression": "\"58%\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " in the MEDIUM setup, which outperforms training the neural tagger on very limited gold data (plain).  Neural NER is "
    },
    {
      "expression": "\"better\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than traditional HMM-based tagging (TnT) (Brants, 2000) and greatly improves by unsupervised word embedding initialization (+Poly). It is noteworthy that zero-shot transfer benefits only to a limiting degree from more source data (F1 increases by almost "
    },
    {
      "expression": "\"3%\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " when training on all English CoNLL data).  To compare cross-lingual transfer to limited gold data (RQ2), we observe that training the neural system on the small amount of data together with Polyglot embeddings is close to the tiny-shot transfer setup.  Few-shot learning greatly improves over zero-shot learning. The "
    },
    {
      "expression": "\"most beneficial\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " way is to add the target data to the source, in comparison to fine-tuning.  In both MEDIUM and LARGE setups are further gains obtained by adding TINY or SMALL amounts of Danish gold data. Interestingly, a) finetuning is less effective; b) it is "
    },
    {
      "expression": "\"better\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " to transfer from a medium-sized setup than from the entire CoNLL source data."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen/_2003_02931v1_355"
  ],
  "datasets": ["datasets/scigen/2003.02931v1-355.json"]
}