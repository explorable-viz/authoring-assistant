{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "In Table 3 we have listed the "
    },
    {
      "expression": "\"average\"",
      "categories": ["average"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " MAP and nDCG scores of the test sets. The "
    },
    {
      "expression": "\"tf-idf model\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " is outperformed by most of the other models. However, "
    },
    {
      "expression": "\"bm25\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", which additionally takes the length of a document into account, performs very "
    },
    {
      "expression": "\"better\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "] than "
    },
    {
      "expression": "\"tf-idf and bm25\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " have the major benefit of well. fast computation. The "
    },
    {
      "expression": "\"feat model\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " slightly outperforms the "
    },
    {
      "expression": "\"auto-rank + feat model\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", which is slightly "
    },
    {
      "expression": "\"better\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than the "
    },
    {
      "expression": "\"auto-rank + bm25 model\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", both of which have the "
    },
    {
      "expression": "\"overall best performance\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". This shows, that the "
    },
    {
      "expression": "\"auto-encoder learns something orthogonal to term frequency and document length\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". The "
    },
    {
      "expression": "\"best model\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " with respect to document ranking is the "
    },
    {
      "expression": "\"auto-rank + feat model\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". In Figure 3 we show the correlation between the different models. Interestingly, the "
    },
    {
      "expression": "\"bm25 and the feat strongly correlate\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " However, the scores of "
    },
    {
      "expression": "\"bm25\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " do not correlate with the scores of the combination of "
    },
    {
      "expression": "\"auto-rank and bm25\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". This indicates, that the model does not primarily learn to use the "
    },
    {
      "expression": "\"bm25 score\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " but also focuses on the the "
    },
    {
      "expression": "\"auto-encoded representation\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". This underlines the hypothesis that the "
    },
    {
      "expression": "\"auto-encoder is able to represent latent features of the relationship of the query terms in the document. rank model\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". The distance features are a strong indicator for the semantic dependency between entities. These relationships need to be learned in the "
    },
    {
      "expression": "\"auto-rank model\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". The cosine similarity of a query and a document (auto/cos) does not yield a good result. This shows that the "
    },
    {
      "expression": "\"auto-encoder has learned many features, most of which do not correlate with our task\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". We also find that "
    },
    {
      "expression": "\"emb\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " does not yield an equal performance to "
    },
    {
      "expression": "\"auto-rank\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". The combination of the"
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen_SuggestionAgent/_9_464"
  ],
  "datasets": ["datasets/scigen_SuggestionAgent/9-464.json"]
}