{
  "testing-variables": {
    "label_f_google": [0.945, 0.950, 0.953, 0.956, 0.960],
    "description_f_glove": [0.905, 0.910, 0.912, 0.915, 0.918],
    "both_f_fasttext": [0.910, 0.914, 0.920, 0.925, 0.930],
    "label_f_fasttext": [0.915, 0.920, 0.923, 0.926, 0.930]
  },
  "paragraph": [
    {
      "type": "literal",
      "value": "For TOP n COS SIM AVG, the tuning data results (Table 2) are somewhat more varied: First, there is no single best performing set of embeddings: Google yields the best F score for the Label setting ("
    },
    {
      "expression": "(findWithKey_ \"_Concept_Input_Embeddings\" \"Google\" tableData)._Label_F",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "), while GloVe (though only barely) leads in the Description setting ("
    },
    {
      "expression": "(findWithKey_ \"_Concept_Input_Embeddings\" \"GloVe\" tableData)._Description_F",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "). This time, it is fastText which produces the best F score in the Both setting, which is also the best overall tuning data F score for TOP n COS SIM AVG ("
    },
    {
      "expression": "(findWithKey_ \"_Concept_Input_Embeddings\" \"fastText\" tableData)._Both_F",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ")."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen/_1904_12550v1_5"
  ],
  "datasets": ["datasets/scigen/1904.12550v1-5.json"]
}