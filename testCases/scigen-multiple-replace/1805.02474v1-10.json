{
  "datasets": [
    {
      "var": "tableData",
      "file": "datasets/scigen/1805.02474v1-10"
    }
  ],
  "imports": [
    "scigen"
  ],
  "variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "As shown in Table 3, BiLSTM gives significantly better accuracies compared to uni-directional LSTM2, with the training time per epoch "
    },
    {
      "type": "expression",
      "expression": "trendWord (findWithKey' \"model\" \"BiLSTM\" tableData).time_s (findWithKey' \"model\" \"LSTM\" tableData).time_s \"growing from\" \"shrinking to\" \"equal to\""
    },
    {
      "type": "literal",
      "value": " "
    },
    {
      "type": "expression",
      "expression": "(findWithKey' \"model\" \"LSTM\" tableData).time_s"
    },
    {
      "type": "literal",
      "value": " seconds to "
    },
    {
      "type": "expression",
      "expression": "(findWithKey' \"model\" \"BiLSTM\" tableData).time_s"
    },
    {
      "type": "literal",
      "value": " seconds. Stacking 2 layers of BiLSTM gives further improvements to development results, with a larger time of "
    },
    {
      "type": "expression",
      "expression": "(findWithKey' \"model\" \"2 stacked BiLSTM\" tableData).time_s"
    },
    {
      "type": "literal",
      "value": " seconds. 3 layers of stacked BiLSTM does not further improve the results. In contrast, S-LSTM gives a development result of "
    },
    {
      "type": "expression",
      "expression": "(findWithKey' \"model\" \"S-LSTM\" tableData).acc"
    },
    {
      "type": "literal",
      "value": "%, which is significantly better compared to 2-layer stacked BiLSTM, with a smaller number of model parameters and a shorter time of "
    },
    {
      "type": "expression",
      "expression": "(findWithKey' \"model\" \"S-LSTM\" tableData).time_s"
    },
    {
      "type": "literal",
      "value": " seconds.  We additionally make comparisons with stacked CNNs and hierarchical attention (Vaswani et al., 2017), shown in Table 3 (the CNN and Transformer rows), "
    },
    {
      "type": "expression",
      "expression": "(findWithKey' \"time_s\" (minimum (map (fun y -> y.time_s) tableData)) tableData).model"
    },
    {
      "type": "literal",
      "value": " is the most efficient among all models compared, with the  "
    },
    {
      "type": "expression",
      "expression": "let pos = findIndex \"model\" \"CNN\" (insertionSort cmpParam tableData) in rankLabel \"smallest\" pos\n"
    },
    {
      "type": "literal",
      "value": " model size. On the other hand, a 3-layer stacked CNN gives an accuracy of "
    },
    {
      "type": "expression",
      "expression": "(fromSome (findWithKey \"model\" \"3 stacked CNN\" tableData)).acc"
    },
    {
      "type": "literal",
      "value": "%, which is also the "
    },
    {
      "type": "expression",
      "expression": "let pos = findIndex \"model\" \"CNN\" (insertionSort cmpTime tableData) in rankLabel \"lowest\" pos\n"
    },
    {
      "type": "literal",
      "value": " compared with BiLSTM, hierarchical attention and S-LSTM. The best performance of hierarchical attention is between single-layer and two-layer BiLSTMs in terms of both accuracy and efficiency. S-LSTM gives significantly better accuracies compared with both CNN and hierarchical attention. Table 3 additionally shows the results of BiLSTM and S-LSTM when external attention is used  Attention leads to improved accuracies for both BiLSTM and S-LSTM in classification, with S-LSTM still outperforming BiLSTM significantly."
    }
  ]
}
