{
  "datasets": [
    {
      "var": "tableData",
      "file": "datasets/scigen/1904.12550v1-5"
    }
  ],
  "imports": [],
  "variables": {},
  "expected": {
    "num_1": "head (map (fun x -> x.label___f) (filter (fun x -> x.concept_input____embeddings == \"Google\") tableData))",
    "num_2": "head (map (fun x -> x.description___f) (filter (fun x -> x.concept_input____embeddings == \"GloVe\") tableData))",
    "num_3": "head (map (fun x -> x.both___f) (filter (fun x -> x.concept_input____embeddings == \"fastText\") tableData))"
  },
  "paragraph": [
    {
      "type": "literal",
      "value": "For TOP n COS SIM AVG, the tuning data results (Table 2) are somewhat more varied: First, there is no single best performing set of embeddings: Google yields the best F score for the Label setting ([REPLACE id=\"num_1\"]), while GloVe (though only barely) leads in the Description setting ([REPLACE id=\"num_2\"]). This time, it is fastText which produces the best F score in the Both setting, which is also the best overall tuning data F score for TOP n COS SIM AVG ([REPLACE id=\"num_3\"])."
    }
  ]
}
