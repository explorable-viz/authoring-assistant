{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "One annotator (one of the authors of this paper) manually assessed the outputs of the models that obtained the "
    },
    {
      "expression": "\"best\"",
      "categories": ["rank"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " development set BLEU score as summarized in "
    },
    {
      "expression": "\"Table 56\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". As we can see from the bottom part of the table, all models struggle more with getting the content right than with producing linguistically correct texts; "
    },
    {
      "expression": "\"70-80%\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " of the texts generated by all models are completely correct linguistically.  Comparing the two datasets, we again observe that the "
    },
    {
      "expression": "\"WebNLG\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " dataset is much more challenging than the "
    },
    {
      "expression": "\"E2E\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " dataset, especially with respect to correctly verbalizing the content.  Moreover, spelling mistakes only appeared in "
    },
    {
      "expression": "\"WebNLG\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " texts, mainly concerning omissions of accents or umlauts.  The most frequent content error in both datasets concerns omission of information.  Information addition and repetition only occur in the "
    },
    {
      "expression": "\"WebNLG\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " dataset. The latter is an especially frequent problem of the character-based model, affecting more than a quarter of all texts.  In comparison, character-based models reproduce the content more faithfully on the "
    },
    {
      "expression": "\"E2E\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " dataset while offering the same level of linguistic quality as word-based models, leading to more correct outputs overall. On the "
    },
    {
      "expression": "\"WebNLG\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " dataset, the word-based model is more faithful to the inputs, probably because of the effective delexicalization strategy, whereas the character-based model errs less on the linguistic side. Overall, the word-based model yields more correct texts, stressing the importance of delexicalization and data normalization in low resource settings."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen/_1810_04864v1_19"
  ],
  "datasets": ["datasets/scigen/1810.04864v1-19.json"]
}