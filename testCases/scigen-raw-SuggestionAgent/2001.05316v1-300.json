{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Various subsets of "
    },
    {
      "expression": "\"authors\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " were chosen and the dataset was truncated to each "
    },
    {
      "expression": "\"author\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " having the same number of samples.  with and without pre-training character level embedding and "
    },
    {
      "expression": "\"comparing\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " the proposed architectures on the held-out dataset.  To illustrate the need of pre-trained character embeddings, we see from III that using a pre-trained embedding increases the accuracy across datasets and the different number of authors, regardless of the amount of data for each author.  "
    },
    {
      "expression": "\"increase\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " the performance "
    },
    {
      "expression": "\"a few degrees\"",
      "categories": ["difference"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ".  we analyzed the importance of pretrained character embedding for author attribution and showed that pre-training can result in "
    },
    {
      "expression": "\"better performances\"",
      "categories": [
        "comparison",
        "average"
      ],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen/_2001_05316v1_300"
  ],
  "datasets": ["datasets/scigen/2001.05316v1-300.json"]
}