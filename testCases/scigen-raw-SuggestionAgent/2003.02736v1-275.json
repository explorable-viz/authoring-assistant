{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Our results are given in "
    },
    {
      "expression": "\"Table 4\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". We found that the "
    },
    {
      "expression": "\"Wikipedia and Twitter datasets\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " contained labels which were "
    },
    {
      "expression": "\"more general\"",
      "categories": ["comparison"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", evidenced by similar high F1 scores from both annotators (> "
    },
    {
      "expression": "\"0.8\"",
      "categories": ["data-retrieval"],
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "). For political speeches, we observed that the human annotators both found many more examples to be check-worthy than were labelled in the dataset."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigen/_2003_02736v1_275"
  ],
  "datasets": ["datasets/scigen/2003.02736v1-275.json"]
}