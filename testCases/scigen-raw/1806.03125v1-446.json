{
  "datasets": [
    "datasets/scigen/1806.03125v1-446.json"
  ],
  "imports": [
    "scigen",
    "util",
    "datasets/scigen/_1806_03125v1_446"
  ],
  "variables": {},
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "In this experiment, we performed text classification among the classes in the Reuters-8 database.  The results can be seen in Table II. The simplest baseline, SA with w2v, achieved an accuracy rate of 78.73%. This  LSA with BOW features was almost 10% more accurate than SA, where the best results with binary weights were achieved with an approximation with 130 dimensions, with TF weights were achieved with 50 dimensions, and with TFIDF weights were achieved with 30 dimensions. SVM with BOW features was about 3% more accurate than LSA, with binary weights leading to a higher accuracy rate.  Among the baselines, the best method was MNB with tfBOW features, with an accuracy of 91.47%,  MSM with w2v had an accuracy rate of 90.62%, with the best results achieved with word subspace dimensions for the training classes ranging from 150 to 181, and for the query ranging from 3 to 217. Incorporating the frequency information in the subspace modeling resulted in higher accuracy, with TFMSM achieving 92.01%, with dimensions of word subspaces"
    }
  ]
}