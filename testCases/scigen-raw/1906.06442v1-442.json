{
  "datasets": [
    "datasets/scigen/1906.06442v1-442.json"
  ],
  "imports": [
    "scigen",
    "util",
    "datasets/scigen/_1906_06442v1_442"
  ],
  "variables": {},
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "To understand how the model treats the tag and what biases it learns from the data, we investigate the entropy of the attention probability distribution, as well as the attention captured by the tag.  For the tagged variants, there is heavy attention on the tag when it is present (Table 6), indicating that the model relies on the information signalled by the tag.  Table 6 reports the average length-normalized Shannon entropy:  The entropy of the attention probabilities from the model trained on BT data is the clear outlier."
    }
  ]
}