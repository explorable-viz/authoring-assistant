{"testing-variables":{},"paragraph":[{"type":"literal","value":"The average performances of LR−syntax and CNN:rand are virtually identical, both for Macro-F1 "},{"expression":"\"FscoreM\"","type":"expression"},{"type":"literal","value":" in Sokolova and Lapalme (2009). F1 and Claim-F1, with a slight advantage for the feature-based approach, but their difference is not statistically significant (p ≤ 0.05). Altogether, these two systems exhibit "},{"expression":"\"better\"","type":"expression"},{"type":"literal","value":" average performances than all other models surveyed here, both those relying on and those not relying on hand-crafted features (p ≤ 0.05). The performance of the learners is quite divergent across datasets, with Macro-F1 scores ranging from "},{"expression":"\"60\"","type":"expression"},{"type":"literal","value":"% ("},{"expression":"\"WTP\"","type":"expression"},{"type":"literal","value":") to "},{"expression":"\"80\"","type":"expression"},{"type":"literal","value":"% ("},{"expression":"\"MT\"","type":"expression"},{"type":"literal","value":"), average "},{"expression":"\"67\"","type":"expression"},{"type":"literal","value":"% (see Table 2). On all datasets, our "},{"expression":"\"best\"","type":"expression"},{"type":"literal","value":" systems clearly outperform both baselines. In isolation, lexical, embedding, and syntax features are most helpful, whereas structural features did not help in most cases. Discourse features only contribute significantly on MT. When looking at the performance of the feature-based approaches, the most striking finding is the importance of lexical (in our setup, unigram) information."}],"variables":{},"imports":["scigen","util","datasets/scigenCL/_1704_07203v3_455"],"datasets":["datasets/scigenCL/1704.07203v3-455.json"]}