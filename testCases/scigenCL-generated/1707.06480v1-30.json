{
  "testing-variables": {},
  "paragraph": [{
    "type": "literal",
    "value": "The results of the pre-selection are reported in Table 1. All syllable-aware models comfortably outperform the Char-CNN when the budget is limited to [REPLACE value=\"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno,\r] parameters. Surprisingly, a pure word-level model, 6 LSTM-Word, also beats the character-aware one under such budget. The three [REPLACE value=\"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno,\r] configurations are Syl-Concat, Syl-Sum, and Syl-CNN-"
  }],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigenCL/_1707_06480v1_30"
  ],
  "datasets": ["datasets/scigenCL/1707.06480v1-30.json"]
}