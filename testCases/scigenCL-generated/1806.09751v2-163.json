{
  "testing-variables": {},
  "paragraph": [{
    "type": "literal",
    "value": "Finally, for the last setting, we tested the system using the three auto-annotation modes (i.e., FA, HFA, and UFA) as shown in Table 3. While the auto-annotation mode can allow us to reduce up to [REPLACE value=\"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno,\r%] of the data pool, this drastic saving also reduces the accuracy of the learned model, achieving, on average, around [REPLACE value=\"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno,\r%] F-Score. Overall, our framework presents a trade off between coverage and annotation cost. The HFA auto-annotation mode shows the benefit, especially in a realistic enterprise setting, when we need to annotate [REPLACE value=\"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno,\r%] of the data to increase F-Score by only [REPLACE value=\"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno,\r%] (when comparing the on average performance of HFA with ESA) is unreasonable. Table 3 appears to show FA being [REPLACE value=\"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno,\r] to EAL in terms of the percentage cut for the Location class, for example. In reality FA reduced sentence annotation by [REPLACE value=\"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno,\r%] to reach [REPLACE value=\"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno,\r] F-Score. But as our testing criteria demanded that we either reach [REPLACE value=\"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno,\r] F-Score or finish all sentences from the pool, FA tried to finish the pool without any further performance improvement on the [REPLACE value=\"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno,\r] F-Score.\n\nIt seems like there's a recurring issue with the text \"[REPLACE value=\"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno,\r%]\" which suggests an error in reading or parsing. This might need to be resolved before accurate Fluid expression replacements can be made based on actual data values. Please provide the correct numerical values that should replace these text sections for accurate annotation."
  }],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigenCL/_1806_09751v2_163"
  ],
  "datasets": ["datasets/scigenCL/1806.09751v2-163.json"]
}