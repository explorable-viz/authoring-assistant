{"testing-variables":{},"paragraph":[{"type":"literal","value":"of results the multimodal The experiments are shown in Table 3. We find that "},{"expression":"\"EF\"","type":"expression"},{"type":"literal","value":">"},{"expression":"\"HF\"","type":"expression"},{"type":"literal","value":">"},{"expression":"\"TFN\"","type":"expression"},{"type":"literal","value":">"},{"expression":"\"LF\"","type":"expression"},{"type":"literal","value":". Unlike Zadeh et al. (2017), here the "},{"expression":"\"EF\"","type":"expression"},{"type":"literal","value":" model outperforms the "},{"expression":"\"TFN\"","type":"expression"},{"type":"literal","value":" model. However, the "},{"expression":"\"TFN\"","type":"expression"},{"type":"literal","value":" model achieved "},{"expression":"\"the best\"","type":"expression"},{"type":"literal","value":" performance on the training and validation sets. Compared to the feature concatenation used in EF, the Cartesian product used in TFN results in "},{"expression":"\"higher\"","type":"expression"},{"type":"literal","value":" dimensionality of the multimodal input vector, which in turn increases the complexity of the model. Similarly, the "},{"expression":"\"HF\"","type":"expression"},{"type":"literal","value":" model has "},{"expression":"\"worse\"","type":"expression"},{"type":"literal","value":" performance than the "},{"expression":"\"EF\"","type":"expression"},{"type":"literal","value":" model here, unlike in Tian et al. (2016). In general, the multimodal models have "},{"expression":"\"better\"","type":"expression"},{"type":"literal","value":" performance than the unimodal models. In fact, the "},{"expression":"\"HF\"","type":"expression"},{"type":"literal","value":" and "},{"expression":"\"LF\"","type":"expression"},{"type":"literal","value":" models have "},{"expression":"\"better\"","type":"expression"},{"type":"literal","value":" performance using single-task learning. For the TFN models, only the S+P model outperforms the S model, although the improvement is not significant. For the EF models, multi-task learning results in "},{"expression":"\"better\"","type":"expression"},{"type":"literal","value":" performance. Dimension of the EF input is 420, for TFN is 65,536. Except that the LF models often have "},{"expression":"\"worse\"","type":"expression"},{"type":"literal","value":" performance than the verbal S+P model. p << 0.001 for TFN S+P and verbal S+P, p = 0.017 for verbal S+P and LF S. p = 0.105 for S TFN and S+P TFN. p = 0.888 for S EF and S+P EF, p = 0.029 for S EF and S+I EF, p = 0.009 for S EF and S+P+I EF."}],"variables":{},"imports":["scigen","util","datasets/scigenCL/_1807_01466v1_259"],"datasets":["datasets/scigenCL/1807.01466v1-259.json"]}