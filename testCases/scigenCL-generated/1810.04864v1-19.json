{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "It seems that there is a repeated error message \"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non è riconosciuto come comando interno o esterno, throughout the paragraph which does not appear to be related to the content of the text. Assuming that this is an artifact and should be ignored, here's how we can annotate the relevant parts:\n\nOne \"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non è riconosciuto come comando interno o esterno, (one of the authors of this paper) manually assessed the outputs of the models that obtained "
    },
    {
      "expression": "\"development set BLEU score\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " as summarized in Table 56. As we can see from the bottom part of the table, all models struggle more with getting the content right than with producing linguistically correct texts; \"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non è riconosciuto come comando interno o esterno, "
    },
    {
      "expression": "\"% of the texts generated by all models are completely correct linguistically.\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". Comparing the two datasets, we again observe that the WebNLG dataset is "
    },
    {
      "expression": "\"better\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than the E2E dataset, especially with respect to correctly verbalizing the content. Moreover, spelling mistakes only appeared in WebNLG texts, mainly concerning omissions of accents or umlauts. The "
    },
    {
      "expression": "\"content error in both datasets concerns omission of information.\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " Information addition and repetition only occur in the WebNLG dataset. The latter is an especially frequent problem of the character-based model, affecting more than a quarter of all texts. In comparison, character-based models reproduce the content more faithfully on the E2E dataset while offering the same level of linguistic quality as word-based models, leading to "
    },
    {
      "expression": "\"outputs overall.\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". On the WebNLG dataset, the word-based model is more faithful to the inputs, probably because of the effective delexicalization strategy, whereas the character-based model errs less on the linguistic side. Overall, the word-based model yields "
    },
    {
      "expression": "\"texts\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " stressing the importance of delexicalization and data normalization in low resource settings.\n\nNote: There are some parts where there is no exact comparative or superlative expression that can be replaced with Fluid, hence phrases like \"outputs overall\" and \"texts\" remain unchanged as they do not directly correspond to a specific value or comparison mentioned."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigenCL/_1810_04864v1_19"
  ],
  "datasets": ["datasets/scigenCL/1810.04864v1-19.json"]
}