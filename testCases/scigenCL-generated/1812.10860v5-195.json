{"testing-variables":{},"paragraph":[{"type":"literal","value":"Table 4 presents an alternative view of the results of the pretraining experiment (Table 2): The table shows "},{"expression":"\"correlations\"","type":"expression"},{"type":"literal","value":" between pairs of target tasks over the space of pretrained encoders. The correlations reflect the degree to which the performance on one target task with some encoder predicts performance on another target task with the same encoder. See Appendix D for the full table and similar tables for intermediate ELMo and BERT experiments. Many "},{"expression":"\"correlations\"","type":"expression"},{"type":"literal","value":" are low, suggesting that different tasks benefit from different forms of pretraining to a substantial degree, and bolstering the observation that no single pretraining task yields good performance on all target tasks. For reasons noted earlier, the models that tended to perform "},{"expression":"\"best\"","type":"expression"},{"type":"literal","value":" overall also tended to overfit the WNLI training set most, leading to a "},{"expression":"\"negative correlation\"","type":"expression"},{"type":"literal","value":" between WNLI and overall GLUE score. STS also shows a "},{"expression":"\"negative correlation\"","type":"expression"},{"type":"literal","value":", likely due to the observation that it does not benefit from LM pretraining. In contrast, CoLA shows a "},{"expression":"\"strong correlation\"","type":"expression"},{"type":"literal","value":" with the overall GLUE scores, but has weak or negative correlations with many tasks: The use of LM pretraining dramatically improves CoLA performance, but most other forms of pretraining have little effect."}],"variables":{},"imports":["scigen","util","datasets/scigenCL/_1812_10860v5_195"],"datasets":["datasets/scigenCL/1812.10860v5-195.json"]}