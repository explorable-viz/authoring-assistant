{"testing-variables":{},"paragraph":[{"type":"literal","value":"Given a sentence, in any language, we evaluate the rank of the corresponding image. The evaluation is again made by batches of 1000. The results are presented in table 2.  The first two lines of the table present the state-of-the-art results, with W2V and FastText embeddings. We can see similar results as in the previous experiment. With BIVEC, we have results close to the "},{"expression":"\"FastText\"","type":"expression"},{"type":"literal","value":" embeddings when training only in English. This time, the recall is "},{"expression":"\"better\"","type":"expression"},{"type":"literal","value":" with an increase of "},{"expression":"\"2.68\"","type":"expression"},{"type":"literal","value":"% for recall@1. When trained with English and French, the recall@1 is increased by "},{"expression":"\"3.65\"","type":"expression"},{"type":"literal","value":"%. This implies, again, that we can improve performance by learning on an additional language.  Our model is able to use the multi-language representing the effectiveness of MUSE embeddings. We train the model with English, and different combinations of French, German and Czech. On English only, we have similar results to the "},{"expression":"\"W2V\"","type":"expression"},{"type":"literal","value":" approach. When adding new languages, we can see a decrease in performance for English. We obtain a "},{"expression":"\"maximum\"","type":"expression"},{"type":"literal","value":" decrease of "},{"expression":"\"2.62\"","type":"expression"},{"type":"literal","value":"% for recall@1 when the models saw English, French, German and Czech.  For image retrieval from a caption in 4 languages, we obtain a "},{"expression":"\"49.38\"","type":"expression"},{"type":"literal","value":"% recall@10 on the Multi30K dataset."}],"variables":{},"imports":["scigen","util","datasets/scigenCL/_1903_11299v3_306"],"datasets":["datasets/scigenCL/1903.11299v3-306.json"]}