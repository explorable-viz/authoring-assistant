{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "The paragraph provided does not contain any explicit values, comparative expressions, or superlative/aggregated expressions that can be replaced with Fluid expressions based on the given criteria.\n\nHowever, if there were such expressions, they would be annotated as follows:\n\nExample:\nIf there was a sentence like \"S-LSTM gives an F1-score of 91.57% on NER dataset,\" it would be annotated as:\n\"S-LSTM gives an F1-score of "
    },
    {
      "expression": "\"91.57\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "% on NER dataset.\"\n\nSince no such expressions exist in the given paragraph, no replacements are made.\n\n**Output:**\n\nfive \"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno, source and six \"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno, target NER data sets, each selected to provide a range of fields (i.e., biology, computer science, medications, local business) and tenors (i.e., encyclopedia articles, journal articles, experimental protocols, online reviews). We use five \"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno, data sets as source data, covering a range of fields (i.e., clinical, biomedical, local business and Wiki with diverse fields) and tenors (i.e., popular reporting, notes, scholarly publications, online reviews and encyclopedia). Details of these target data are listed in Table 2."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigenCL/_1904_00585v2_68"
  ],
  "datasets": ["datasets/scigenCL/1904.00585v2-68.json"]
}