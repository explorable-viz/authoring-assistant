{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Table 2 presents the results of our method comparing them against recent state-of-the-art supervised models and the simple n-gram language model used by Bryant and Briscoe (2018). A key result of Table 2 is that Transformer Language Models prove to be "
    },
    {
      "expression": "\"competitive\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " baseline to legitimate Grammatical Error Correction systems on their own. Across the board, Transformer Models are able to "
    },
    {
      "expression": "\"the simple n-gram model\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " and even approach the performance of supervised GEC systems. We see that their performance is nearly identical with GPT-2 leading by a small margin in the CoNLL14 dataset. BERT surpasses the n-gram baseline overall, it achieves "
    },
    {
      "expression": "\"performance\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than the rest in terms of precision and F0.5 score.\n\nNote: The placeholder \"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non ï¿½ riconosciuto come comando interno o esterno, \u201c seems to be an error message or extraneous text that is not part of the paragraph and thus has been removed from the annotation."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigenCL/_1906_01733v1_447"
  ],
  "datasets": ["datasets/scigenCL/1906.01733v1-447.json"]
}