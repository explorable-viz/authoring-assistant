{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "It looks like there is a repetition of an error message within the text that does not pertain to any meaningful value or comparison and can be ignored for this task. Here\u2019s how the paragraph should be annotated based on the given criteria:\n\nWe also report the average number of generated keyphrases per document, denoted as  \"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non ï¿½ riconosciuto come comando interno o esterno,\r. The results are shown in Table 4, where oracle is a model that always generates the ground-truth keyphrases. The resultant MAEs demonstrate that our deep reinforced models notably "
    },
    {
      "expression": "\"outperform\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " the baselines on predicting the number of absent keyphrases and "
    },
    {
      "expression": "\"slightly outperform\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " the baselines on predicting the number of present keyphrases. Moreover, our deep reinforced models generate "
    },
    {
      "expression": "\"more\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " absent keyphrases than the baselines. Besides, the baseline models and our reinforced models generate similar numbers of present keyphrases, while our reinforced models achieve "
    },
    {
      "expression": "\"higher\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " F -measures, implying that our methods generate present keyphrases "
    },
    {
      "expression": "\"better\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than the baselines."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigenCL/_1906_04106v1_358"
  ],
  "datasets": ["datasets/scigenCL/1906.04106v1-358.json"]
}