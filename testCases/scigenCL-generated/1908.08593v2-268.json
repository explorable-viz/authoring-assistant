{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Table 1 shows that finetuned BERT outperforms pre-trained BERT by a significant margin on all the tasks (with an average of "
    },
    {
      "expression": "\"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non ï¿½ riconosciuto come comando interno o esterno,\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " points of absolute difference). BERT with weights initialized from normal distribution and further fine-tuned for a given task consistently produces "
    },
    {
      "expression": "\"lower\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " scores than the ones achieved with pre-trained BERT. In fact, for some tasks (STS-B and QNLI), initialization with random weights yields "
    },
    {
      "expression": "\"worse\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " performance than pre-trained BERT without fine-tuning."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigenCL/_1908_08593v2_268"
  ],
  "datasets": ["datasets/scigenCL/1908.08593v2-268.json"]
}