{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "We use Amazon Mechanical Turk to label around \"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno, \\ potentially derogatory tweets Table 1 compares different labelsets that exist in the literature. For instance, Waseem and Hovy (2016) use racist, sexist, and normal as labels; Davidson et al. (2017) label their data as hateful, offensive (but not hateful), and neither, while ElSherief et al. (2018) present an English dataset that records the target category based on which hate speech discriminates against people, such as ethnicity, gender, or sexual orientation and ask human annotators to classify the tweets as \"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno, \\ and "
    },
    {
      "expression": "\"not\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " \"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno, \\. Founta et al. (2018) label their data as offensive, abusive, hateful, aggressive, cyberbullying, spam, and normal.\n\nNote: The string \"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno, \\ appears to be an error or irrelevant information in the context provided, as it does not seem to contribute meaningful comparative or superlative expressions within the paragraph. Only the word \"not\" is annotated here as a comparative expression."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigenCL/_1908_11049v1_345"
  ],
  "datasets": ["datasets/scigenCL/1908.11049v1-345.json"]
}