{"testing-variables":{},"paragraph":[{"type":"literal","value":"We test an unsupervised setting using (1) the algorithm proposed in Section 4.4 with EmbDI local embeddings, and (2) an existing matching system with both pre-trained embeddings (SeepP) and our local embeddings (SeepL). Pre-trained embeddings for tokens and tuples have been obtained from Glove. Table 3 reports the results w.r.t. manually defined attribute matches. The simple unsupervised method with EmbDI local embeddings outperforms the baseline "},{"expression":"\"in terms of Fmeasure\"","type":"expression"},{"type":"literal","value":" in all scenarios. Results of RefS are "},{"expression":"\"the best\"","type":"expression"},{"type":"literal","value":" because of the high overlap between its datasets. The baseline improves when it is executed with EmbDI local embeddings, showing their "},{"expression":"\"superior quality w.r.t. pre-trained ones\"","type":"expression"},{"type":"literal","value":". The Basic local embeddings lead to "},{"expression":"\"0\"","type":"expression"},{"type":"literal","value":" attribute matches. We also observe that results for SeepPreTrain depend on the quality of the original attribute labels. If we replace the original (expressive and correct) labels with synthetic ones, Seep-PreTrain obtains F-measure values between [.30] and [.38]. Local embeddings from EmbDI do not depend on the presence of the attribute labels. Similarly, decreasing the size of the walks to 5 for the SM task raises the F-measure for RefL to [.92] (from [.77])."}],"variables":{},"imports":["scigen","util","datasets/scigenCL/_1909_01120v1_340"],"datasets":["datasets/scigenCL/1909.01120v1-340.json"]}