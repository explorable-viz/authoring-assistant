{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "We tried to combine different features shown in Table 6 for the interrogative-word classifier. The first model is only using the BERT token embedding. The second model is the previous one with the entity type of the answer as an additional feature. The performance of this model is "
    },
    {
      "expression": "\"than\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " the first one but it is not enough to be utilized effectively for our pipeline. As we can see, the performance noticeably increased, which indicates that answer information is the key to predict the interrogative word needed. The fourth model, clearly outperforms the previous one. The fifth model is the same as the previous one but with the addition of the entity type embedding of the answer. The combination of the three features (answer, answer entity type, and passage) yields "
    },
    {
      "expression": "\"performance\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": "."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigenCL/_1910_13794v1_112"
  ],
  "datasets": ["datasets/scigenCL/1910.13794v1-112.json"]
}