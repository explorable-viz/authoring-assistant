{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "Sure, let's clean up the paragraph and annotate the expressions as specified:\n\nThe compression results on the six adopted datasets, including parameter size, inference speedup and classification accuracy, are summarized in Table 1. Overall speaking, on all the evaluated datasets, the proposed AdaBERT method achieves significant efficiency improvement while maintaining performance. Compared to the BERT12-T, the compressed models are smaller in parameter size and faster in inference speed with an average performance degradation of "
    },
    {
      "expression": "\"%\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ".\nComparing with structure-heterogeneous method, BiLSTMSOF, AdaBERT searches CNN-based models and achieves improvements, especially on the MNLI dataset.\nComparing with different Transformers-based compression baselines, the proposed AdaBERT method is faster than the fastest baseline, TinyBERT4, and achieves performance with the two baselines that have the averaged accuracy, BERT6-PKD and TinyBERT4.\n\nRevised Annotation:\n\nThe compression results on the six adopted datasets, including parameter size, inference speedup and classification accuracy, are summarized in Table 1. Overall speaking, on all the evaluated datasets, the proposed AdaBERT method achieves significant efficiency improvement while maintaining "
    },
    {
      "expression": "\"performance\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". Compared to the BERT12-T, the compressed models are "
    },
    {
      "expression": "\"smaller\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " in parameter size and "
    },
    {
      "expression": "\"faster\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " in inference speed with an average performance degradation of "
    },
    {
      "expression": "\"%\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ".\nComparing with structure-heterogeneous method, BiLSTMSOF, AdaBERT searches CNN-based models and achieves "
    },
    {
      "expression": "\"improvements\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", especially on the MNLI dataset.\nComparing with different Transformers-based compression baselines, the proposed AdaBERT method is "
    },
    {
      "expression": "\"faster\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than the fastest baseline, TinyBERT4, and achieves "
    },
    {
      "expression": "\"performance\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " with the two baselines that have the "
    },
    {
      "expression": "\"averaged accuracy\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ", BERT6-PKD and TinyBERT4."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigenCL/_2001_04246v1_429"
  ],
  "datasets": ["datasets/scigenCL/2001.04246v1-429.json"]
}