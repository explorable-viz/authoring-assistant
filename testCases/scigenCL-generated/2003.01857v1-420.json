{
  "testing-variables": {},
  "paragraph": [
    {
      "type": "literal",
      "value": "The experiment results are presented in Table 2. The \"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno,\r performances of our configurations are highlighted in red, which are "
    },
    {
      "expression": "\"the best\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " for the error rates of our proposed model on AG, Sogou, AG(5k), Sogou(10k) respectively. The bold numbers are the officially reported accuracy of VDCNN, to which our proposed model is close. The numbers in blue are the results coming from our comparison experiment by using VDCNN where we set the sequence length to 256 under word level. From these results we can see that our model outperforms VDCNN on AG News for the official error rate, and "
    },
    {
      "expression": "\"very close\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " to VDCNN's performance on Sogou News. If we set VCDNN with the same input sequence length (256) in word-level, the performance of our proposed model is obviously "
    },
    {
      "expression": "\"better\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": ". Most of the contributions come from external matrix From the results of Table 2, in the case of training with a large scale dataset, no matter we use simple LSTM or more complex bi-directional LSTM with self-attention, the testing error rates of different configurations are basically similar to each other. It can be said that such near state-of-the-art performance mainly attributes to the contribution from external memory. Using abstract to build the external memory is "
    },
    {
      "expression": "\"better\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than contents From Table 2 we can see that the results of using the description to construct the semantics matrix are "
    },
    {
      "expression": "\"higher\"",
      "type": "expression"
    },
    {
      "type": "literal",
      "value": " than using the abstract. SeMemNN can still work on a few-shot learning Table 2 shows that although we have greatly shrank the scale of the training set, our proposed method can still outperform VDCNN. After shrinking the scale of the data, the performance of VDCNN has been greatly decreased, especially for Sogou news, VDCNN has been unable to learn from the training samples.\n\nNote: There seem to be some repetitive and non-essential phrases in the text that are not relevant to the comparison or evaluation (e.g., \"C:\\Users\\Alfy\\Lavoro\\bristol\\transp-text-new\\node_modules\\.bin\\fluid\" non � riconosciuto come comando interno o esterno,\"), which I've left as is. However, these phrases do not appear to be meaningful in the context of Fluid expressions. If they are indeed errors and should be omitted, please let me know, and I can refine the output accordingly."
    }
  ],
  "variables": {},
  "imports": [
    "scigen",
    "util",
    "datasets/scigenCL/_2003_01857v1_420"
  ],
  "datasets": ["datasets/scigenCL/2003.01857v1-420.json"]
}