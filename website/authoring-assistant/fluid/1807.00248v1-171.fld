import scigen
import util
import datasets.scigen_SuggestionAgent._1807_00248v1_171

"""
	Table 1 lists all hyper-parameters which have all been chosen using only  ${"training"}  and  ${"validation"}  data. The two encoders have been implemented using a  ${"Bidirectional Long Short-Term Memory (B-LSTM)"}  ( ${"Hochreiter and Schmidhuber, 1997"} ) while the decoder uses a unidirectional  ${"LSTM"} . Both the encoders and the decoder use  ${"two"}  hidden layers. For the attention network, we have used the OpenNMT's general option ( ${"Luong et al., 2015"} ).
"""
