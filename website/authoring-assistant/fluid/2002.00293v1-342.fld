import scigen
import util
import datasets.scigen_SuggestionAgent._2002_00293v1_342

"""
	For example,  ${"RoBERTa"}  trained on  ${"DRoBERTa"}  reaches  ${"38.9"} F1 on  ${"DRoBERTa"} , and this number further increases to  ${"47.2"} F1 when including  ${"SQuAD"}  during training (cf. Table 6).  In Table 6 we show experimental results for the same models and training datasets, but now including  ${"SQuAD"}  as additional training data. In this training setup we generally see improved generalisation to  ${"DBiDAF"} ,  ${"DBERT"} , and  ${"DRoBERTa"} . Interestingly, the relative differences between  ${"DBiDAF"} ,  ${"DBERT"} , and  ${"DRoBERTa"}  as training set used in conjunction with  ${"SQuAD"}  are now much diminished, and especially  ${"DRoBERTa"}  as (part of the) training set now generalises substantially  ${"better"} .  ${"RoBERTa"}  achieves the strongest results on any of the  ${"DBiDAF"} ,  ${"DBERT"} , and  ${"DRoBERTa"}  evaluation sets, in particular when trained on  ${"DSQuAD+DRoBERTa"} .  we identify a risk of datasets constructed with weaker models in the loop becoming outdated. For example,  ${"RoBERTa"}  achieves  ${"58.2"} EM/ ${"73.2"} F1 on  ${"DBiDAF"} , in contrast to  ${"0.0"} EM/ ${"5.5"} F1 for  ${"BiDAF"}  – which is not far from non-expert human performance of  ${"62.6"} EM/ ${"78.5"} F1.  We furthermore observe a gradual decrease in generalisation to  ${"SQuAD"}  when training on  ${"DBiDAF"}  towards training on  ${"DRoBERTa"} . This suggests that the stronger the model used in the annotation loop, the more dissimilar the data distribution becomes from the original  ${"SQuAD"}  distribution. We will later find further support for this explanation in a qualitative analysis (Section 5). It may however also be due to a limitation of BERT and RoBERTa – similar to BiDAF – in learning from a data distribution designed to beat these models; an even stronger model might learn more e.g. from  ${"DRoBERTa"} .
"""
