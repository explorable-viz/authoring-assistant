import scigen
import util
import datasets.scigen_manual_old._1805_02474v1_10
let model_ name = model name tableData
in

"""
	As shown in Table 3, BiLSTM gives significantly ${trendWord (model_ "BiLSTM")._Acc (model_ "LSTM")._Acc betterWorse} accuracies compared to uni-directional LSTM2, with the training time per epoch ${trendWord (model_ "BiLSTM")._Time_s (model_ "LSTM")._Time_s growShrink} from ${(model_ "LSTM")._Time_s} seconds to ${(model_ "BiLSTM")._Time_s} seconds. Stacking 2 layers of BiLSTM gives ${trendWord (model_ "2 stacked BiLSTM")._Acc (model_ "BiLSTM")._Acc improvements} to development results, with a ${trendWord (model_ "2 stacked BiLSTM")._Time_s (model_ "BiLSTM")._Time_s smallerHigher} time of ${(model_ "2 stacked BiLSTM")._Time_s} seconds. 3 layers of stacked BiLSTM ${trendWord (model_ "3 stacked BiLSTM")._Acc (model_ "BiLSTM")._Acc improve} the results. In contrast, S-LSTM gives a development result of ${(model_ "S-LSTM")._Acc} %, which is significantly ${trendWord (model_ "S-LSTM")._Acc (model_ "2 stacked BiLSTM")._Acc betterWorse} compared to 2-layer stacked BiLSTM, with a ${trendWord (model_ "S-LSTM")._num_Param (model_ "2 stacked BiLSTM")._num_Param smallerHigher} number of model parameters and a ${trendWord (model_ "S-LSTM")._Time_s (model_ "2 stacked BiLSTM")._Time_s shorterLonger} time of ${(model_ "S-LSTM")._Time_s} seconds.  We additionally make comparisons with stacked CNNs and hierarchical attention (Vaswani et al., 2017), shown in Table 3 (the CNN and Transformer rows), ${(findWithKey_ "_Time_s" (minimum (map (fun y -> y._Time_s) tableData)) tableData)._Model} is the ${rankLabel "most efficient" (findIndex "_Model" "CNN" (insertionSort (fun a b -> a._Time_s < b._Time_s) tableData))} among all models compared, with the ${rankLabel "smallest" (findIndex "_Model" "CNN" (insertionSort (fun a b -> a._num_Param < b._num_Param) tableData))} model size. On the other hand, a 3-layer stacked CNN gives an accuracy of ${(model "3 stacked CNN" tableData)._Acc} %, which is also the ${rankLabel "lowest" (findIndex "_Model" "CNN" (insertionSort (fun a b -> a._Time_s < b._Time_s) tableData))} compared with BiLSTM, hierarchical attention and S-LSTM. The ${rankLabel "best" (findIndex "_Model" "S-LSTM+Attention" (insertionSort (fun a b -> b._Acc < a._Acc) tableData))} performance of hierarchical attention is obtained by S-LSTM+Attention in terms of both accuracy and efficiency. S-LSTM gives significantly ${trendWord (model_ "S-LSTM")._Acc (model_ "CNN")._Acc betterWorse} accuracies compared with both CNN and hierarchical attention. Table 3 additionally shows the results of BiLSTM and S-LSTM when external attention is used. Attention leads to improved accuracies for both BiLSTM and S-LSTM in classification, with S-LSTM still ${trendWord (model_ "S-LSTM")._Acc (model_ "BiLSTM")._Acc underOverPerforming} BiLSTM significantly.
"""
